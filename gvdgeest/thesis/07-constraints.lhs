%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Chapter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{A framework for overloading resolution}
\label{ch:constraints}
% In this first chapter I want to give a type theoretic overview of the framework:\\
% - So I speak about qualifiers, types, classes, simplification, entailment, evidence\\
% - But not about code generation, unique identifiers, trees, graphs, chrs\\
% - In this chapter I want also make clear how the interface look like\\
% 
% Terminology: qualifiers, classes, context, evidence, proof, simplification, entailment, types, solution, state, unification, substitution\\
% 
% Main question:
% - How can we resolve overloading and extensions to overloading using a constraint based framework?
%
% Questions:
% - What are the requirements for this framework?
% - How is the overloading problem formulated in constraints?
%   - When are the constraints solved?
%   - What is the syntax and semantics of the constraints?
% 
% - How can we solve constraints with CHRs?
%   - What are Constraint Handling Rules?
%   - Which CHR's are generated for a class declaration?
%   - Which CHR's are generated for an instance declaration?
%
% - How does the framework resolve overloading?
%    - What must be the properties of the qualifiers, which functions are defined on them?
%    - What is the interface of this framework?
%    - How does the framework solve constraints?
%    - What is the interaction between instantiation/skolemization/generalization and this framework?
%    - How does the framework check instance declarations?

In this chapter we present the initial version of a framework for the resolution of overloading.
This version resolves overloading and reports unresolved predicates as an error.
In the next chapters we extend this version to support code generation, local instances, and other type class extensions.

\section{Introduction}
Multiple compilers should be able to use our framework to resolve overloading.
This means that we cannot depend on how a particular compiler uses this framework.
We accomplish this by introducing two abstractions:

First, we formulate the resolution of overloading as a constraint problem.
Constraint programming yields several advantages~\citep{aiken99introduction}:
The most important advantage is separation of concerns; that is, the specification is separated from the implementation.
Generation of constraints is the specification of the analysis; solving of constraints the implementation.
The constraints are generated by a compiler and this framework computes a solution for those constraints.
Furthermore, class and instance declarations are translated into Constraint Handling Rules (CHRs) and the framework uses these CHRs to solve the constraints.

Second, we do not make any assumption about the structure of the predicate language.
Instead, we require that a number of functions are implemented on the predicates.
This is accomplished by using type classes as the abstraction mechanism in our implementation.

In this chapter we formulate the overloading problem in terms of a constraint language.
Then we show how CHRs can be used to solve overloading constraints and present a translation from class and instance declarations into CHRs.
Finally, we describe the implementation of this framework and show the interaction between CHR solving and generalization.

\section{Constraints for overloading}
In this section we explain how the problem of resolving overloading can be formulated into a constraint language.
Our approach is based on the formulation in Top~\citep{heeren05}.
We use two different types of constraints:
First, the |(Assume pi)| constraint which means that we have an assumption for the qualifier |pi|.
Second, the |(Prove pi)| constraint which means that we have a proof obligation for the qualifier |pi|.
For the moment we do not give a precise specification of a qualifier, but leave it abstract.
However, in the examples we use type class qualifiers to explain the meaning of the constraints.

> CalC   ::=   Prove   pi
>        |     Assume  pi

Overloading is resolved if all |Prove| constraints are entailed by |Assume| constraints.
Consider for example the equality function |(==)| of type |forall a . Eq a => a -> a -> Bool|.
If we use this function, then its type is instantiated with a fresh type variable, say |v1|.
We have to proof that equality is defined on the type |v1| because the type class qualifier |Eq a| is part of the type scheme.
For that reason, we generate the constraint |Prove(Eq v1)| after instantiating the type.
Later in the type inference process we may infer that |v1| is actually of type |Int|.
If we assume that the standard instance for equality on integers is defined, then we are able to solve |Prove(Eq Int)| because |{} entails {Eq Int}|.
In this chapter we use the entailment relation |(entails)| introduced in Chapter~\ref{ch:preliminaries} (figures \ref{basicent} and \ref{classent}).

It is not always possible to directly fulfill proof obligations.
Consider for example the following function:
> max x y
>  | x >= y     = x
>  | otherwise  = y
The overloaded operator |>=| is used in the function |max|.
This operator has the type |forall a . Ord a => a -> a -> Bool| and is instantiated with the fresh type variable |v2|.
We do not acquire more type information for the type variable |v2|, so we end up with the constraint |Prove(Ord v2)|.
The inferred type for the function |max| is |v2 -> v2 -> v2|.
After generalizing this type we get the type scheme: |forall a . Ord a => a -> a -> a|.
The type class qualifier |Ord a| is part of the generalized type because there was a remaining |Prove| constraint concerning the type variable |v2|.
Because the type class qualifier |Ord v2| is generalized, we add the constraint |Assume(Ord v2)| and then |{Ord v2} entails {Ord v2}| trivially holds.

We also generate |Assume| constraints for each qualifier in the context of an explicitly typed function.
Consider for example the following function:
> elem :: Ord a => a -> [a] -> Bool
> elem x []       = False
> elem x (y:ys)   = x == y || elem x ys
The type signature of the function |elem| is skolemized using a fresh type constant, for example |c1|.
Skolemization of the type signature results in the constraint |Assume(Ord c1)|.
The use of the two overloaded functions |(==)| and |elem| result in the constraints |Prove(Eq v1)| and |Prove(Ord v2)|, respectively.
Later in the type inference process we infer that the type variables |v1| and |v2| are equal to |c1|.
We then have to solve the following set of constraints: |{Assume(Ord c1), Prove(Eq c1), Prove(Ord c1)}|.
Overloading in the function |elem| is resolved because the qualifier in the |Assume| constraint entails the qualifiers in the |Prove| constraints: |{Ord c1} entails {Eq c1, Ord c1}|.

\begin{df}[Constraint Satisfaction]
Satisfaction of |Prove| and |Assume| constraints is defined as follows.
Consider a solution |Theta| which consists of a set of assumed qualifiers |PiTheta|.
A |Prove| constraints is satisfied if the corresponding qualifier is entailed by the set of assumed qualifiers |PiTheta|.
> Theta solves Prove   pi  ^^   isdef     ^^    PiTheta entails ThetaQ
> Theta solves Assume  pi  ^^   isdef     ^^    ThetaQ insign PiTheta
Furthermore, an |Assume| constraint is solved if the assumed qualifier is an element of |PiTheta|.
\end{df}

\section{Resolving overloading with CHRs}
\label{s::chrsolver}
Until now we have only given a declarative specification of entailment.
In this section we investigate whether it is possible to formulate the entailment check with Constraint Handling Rules (CHRs).

\subsection{Constraint handling rules}
CHRs~\citep{fruhwirth95chrs} are a high-level declarative language extension especially designed for writing constraint solvers.
CHRs are often embedded in a host language: constraints are defined in CHRs, but auxiliary computations are executed in the host language.
CHRs operate on a set of constraints and rewrite constraints into simpler ones until they are solved.
We use two types of CHRs with the following syntax:
%{
%format || = "|"
>  H1, ... , Hi <=>  G1, ... , Gj ^^ || ^^ B1, ... , Bk      ^^  (simplification)
>  H1, ... , Hi ==>  G1, ... , Gj ^^ || ^^ B1, ... , Bk      ^^  (propagation)
>
>  (i > 0, j >= 0, k >= 0)
%}
The constraints |(H1, ..., Hi)| are the {\it head} of a CHR, the conditions |(G1, ..., Gj)| are the {\it guard} of a CHR, and the constraints |(B1, ..., Bk)| are the {\it body} of a CHR.
The empty constraint set is abbreviated with |true|.
Operationally, a simplification rule replaces the set of constraints in the head by the constraints in the body when the conditions in the guard are satisfied.
A propagation rule adds the constraints in the body if the constraints in the head are present and the conditions in the guards are satisfied.
A propagation rule can be applied infinitely many times, but non-termination is avoided by applying a propagation rule only once to every constraint in the constraint set.
CHRs can be given a declarative semantics~\citep{fruhwirth95chrs}.
A simplification is a logical equivalence if the guards are satisfied:
> forall xbar forall ybar ((G1 && ... && Gj) -> (H1 && ... && Hi <-> exists zbar (B1 && ... && Bk))
Similarly, a propagation is an implication if the guards are satisfied:
> forall xbar forall ybar ((G1 && ... && Gj) -> (H1 && ... && Hi -> exists zbar (B1 && ... && Bk)))
The sequences of variables |xbar| and |ybar| are scoped over the whole CHR.
The variables |xbar| occur in the head of a CHR and the variable |ybar| in the guard.
On the other hand, the variables |zbar| are only scoped over the body of a CHR.

\subsection{Formulating entailment with CHRs}
The entailment relation |(P entails Q)| allows us to check whether it is possible to deduce the predicates in Q from those in P.
We have to perform two steps to formulate this relation into CHRs:
The first step is called simplification where we try to find the minimum set of predicates |P| given |Q| where |P entails Q|.
This step is also called context reduction.
The second step is only performed if there are |Assume| constraints, and checks whether the set of predicates |P| from the first step are entailed by the predicates in the |Assume| constraints.
Simplification is applied to |Prove| constraints and the entailment check matches |Prove| constraints against |Assume| constraints.

\subsubsection*{Simplification}
Simplification itself consists of three steps: removal of duplicate constraints, simplification using instance declarations, and simplification using the class hierarchy.
We get removal of duplicate constraints for free, because the CHR solver operates on a set of constraints.

To simplify |Prove| constraints we generate CHRs for each class and instance declaration.
In this section we present a number of example translations.
In the next section we present the systematic translation.
Consider the following class declarations:
> class Eq  a                ^^   ^^     --   (C1)
> class Eq  a   => Ord a     ^^   ^^     --   (C2)
> class Ord a   => Real a    ^^   ^^     --   (C3)
> instance Eq a => Eq [a]    ^^   ^^     --   (I1)
The following CHRs are generated for these declarations (note that |a| is an implicitly universally quantified variable in each CHR):
> Prove(Eq a)    , Prove(Ord a)    <=> Prove(Ord a)    ^^ ^^ -- (C2)
> Prove(Ord a)   , Prove(Real a)   <=> Prove(Real a)   ^^ ^^ -- (C3)
> Prove(Eq [a])                    <=> Prove(Eq a)     ^^ ^^ -- (I1)
If we apply the rule above on the constraint set |{Prove(Eq [v1]), Prove(Ord v1), Prove(Real v1)}| we could get the following derivation:
>           ^^  {Prove(Eq [v1])  , Prove(Ord v1), Prove(Real v1)}
> deriv(I1) ^^  {Prove(Eq v1)    , Prove(Ord v1), Prove(Real v1)}
> deriv(C2) ^^  {Prove(Ord v1)   , Prove(Real v1)}
> deriv(C3) ^^  {Prove(Real v1)}
First, the rule |I1| is applied, then |C2|, and finally |C3|, but the following derivation is also possible:
>           ^^  {Prove(Eq [v1])  , Prove(Ord v1), Prove(Real v1)}
> deriv(C3) ^^  {Prove(Eq [v1])  , Prove(Real v1)}
> deriv(I1) ^^  {Prove(Eq v1)    , Prove(Real v1)}
This shows that the rules are not confluent.
A set of rules is {\it confluent} if from any given state every possible order of rule applications ends in the same final state.
By adding the following rule we make our rules confluent:
> Prove(Eq a)    , Prove(Real a)    <=> Prove(Real a)
This means that we have to add a rule for every superclass of a class, and not only for the direct superclasses.
In other words, we have to explicitly add the transitive closure of the superclass relation to the CHRs used for simplification.

\subsubsection*{Entailment}
Until now we have only presented the rules to simplify |Prove| constraints.
The second step is to check whether the predicates in the |Prove| constraints match with the predicates in the |Assume| constraints.
Therefore we introduce the following CHR:
> Prove p, Assume p <=> Assume p ^^ ^^ -- (E)
This rule means that the proof obligation |p| can be removed if we have an assumption for |p|.
Note that this rule abstracts over the predicate language used.
Recall the function |elem|:
> elem :: Eq a => a -> [a] -> Bool
> elem x []       = False
> elem x (y:ys)   = x == y || elem x ys
If the explicit type signature of |elem| is skolemized with the fresh type constant |c1| we eventually have to solve the set of constraints: |{Prove (Eq c1), Assume (Eq c1)}|.
This set can easily be solved by applying rule |E|.
But giving the following signature for |elem| is also correct:
> elem :: Real a => a -> [a] -> Bool
The current rules are not sufficient to solve this problem.
We not only have to simplify proof obligations, but also propagate assumptions.
If there is an assumption for |Ord a| then also all superclasses of |Ord a| can be assumed.
Therefore we introduce a propagation CHR for each class declaration:
> class Eq  a   => Ord a                    -- (C2)
> class Ord a   => Real a                   -- (C3)
>
> Assume(Ord a)    ==> Assume(Eq a)  ^^ ^^  -- (CA2)
> Assume(Real a)   ==> Assume(Ord a) ^^ ^^  -- (CA3)
Now we are able to solve the following set of constraints:
>            ^^   {Prove(Eq c1), Assume(Real c1)}
> deriv(CA3) ^^   {Prove(Eq c1), Assume(Real c1), Assume(Ord c1)}
> deriv(CA2) ^^   {Prove(Eq c1), Assume(Real c1), Assume(Ord c1), Assume(Eq c1)}
> deriv(E)   ^^   {Assume(Real c1), Assume(Ord c1), Assume(Eq c1)}
The predicates in the |Assume| constraints entail those in the |Prove| constraints if there are no |Prove| constraints left after solving.

We have shown how we can formulate the entailment check with CHRs.
In the next section we present the first implementation of the framework together with functions for generating CHRs from class and instance declarations.

\subsection{A Haskell CHR solver}
In order to solve constraints with CHRs we have implemented a basic CHR solver in Haskell.
This solver is used by the framework, but could also be replaced by another CHR solver.
We do not explain the implementation of this solver, but only present the interface.
We represent a CHR with the following datatype:
> data CHR c s = CHR   {   head    :: [c]
>                      ,   guard   :: (s -> Maybe s)
>                      ,   body    :: [c]
>                      }
The datatype CHR is parametrized with two type variables: |c| represents the type of the constraint, |s| represents the type of the substitution.
A successful match of the head of a CHR with actual constraints results in a substitution.
Variables in the head of the CHR are bound to values in this substitution.
The guard is a function which gets this substitution as a parameter.
The guard returns a new substitution if the conditions in the guards are satisfied, otherwise the guard returns |Nothing|.
This substitution is applied to the body of the CHR after the substitution resulting from the head is applied.

We introduce two operators to construct simplification and propagation CHRs, respectively:
> infix 1 <=>, ==>
> (<=>), (==>) :: Monoid s => [p] -> [p] -> CHR p s
> hs <=>  bs = CHR hs emptyGuard bs
> hs ==>  bs = hs <=> (hs ++ bs)
>
> emptyGuard :: Monoid s => t -> Maybe s
> emptyGuard = const (Just mempty)
>
> infixr 0 |>
> (|>) :: CHR p s -> (s -> Maybe s) -> CHR p s
> (|>) (CHR hs _ bs) g = CHR hs g bs
We represent both propagation and simplification rules with the CHR datatype.
A propagation rule is immediately translated into a simplification rule when constructing it with the operator |(==>)|.
This is achieved by appending the head of the propagation rule to the body of the simplification rule.
These operators construct CHRs with a guard that always returns the empty substitution.
Note that the identifier |mempty| is from the |Monoid| class.
A guard can be attached to a CHR with the operator |(||>)|.

The following type class is used to support matching of constraints:
> class (Ord c, Monoid s) => Matchable c s | c -> s where
>   match  :: c -> c -> Maybe s
>   subst  :: s -> c -> c
>
>   match x y  | x == y     = Just mempty
>              | otherwise  = Nothing
>   subst = flip const
The default implementation of this class is matching on syntactic equality.
An instance of this class must be given for the type of the constraints used.
Also more advanced forms of matching with patterns are possible.
The function |match| is not symmetric, in other words, there are two values: |x, y| where |match x y /= match y x|.
The function |match| expects a constraint as left hand side and a constraint of the head of a CHR as right hand side.
The head constraint is matched against the constraint and when the match is successful a substitution is returned.
The following QuickCheck~\citep{quickcheck} property should hold:
> propMatch c h =
>   case match c h of 
>     Just s   -> property (c == subst s h)
>     Nothing  -> property ()
A constraint |c| should be equal to the resulting substitution applied to the head if the constraint matches with the head.
The asymmetry is also the reason why there is no need to instantiate a CHR first with fresh variables as with instantiating type schemes.
The substitution is only applied to the CHR and not on the constraints, therefore the variables of a CHR will never leak to the constraints.

Finally, we introduce the function that solves a set of constraints given a list of CHRs:
> chrSolve :: Matchable c s => [CHR c s] -> Set c -> Set c
For convenience, we also introduce a function that solves a list of constraints using CHRs. 
Internally, the list is converted into a set and visa versa:
> chrSolveList :: Matchable c s => [CHR c s] -> [c] -> [c]
> chrSolveList chrs cs = Set.toList (chrSolve chrs (Set.fromList cs))


% First version of the framework
%include 07-implementation.lhs

\section{Conclusion}
In this chapter we have shown that is possible to formulate the resolution of overloading as a constraint problem using |Prove| and |Assume| constraints.
Furthermore, we have shown how those constraints can be simplified using Constraint Handling Rules (CHRs).
We not only presented CHRs to simplify |Prove| constraints, but also presented CHRs that remove |Prove| constraints when  entailed by |Assume| constraints.
We have presented a systematic translation from class and instance declarations into CHRs and during this translation we also check if the class hierarchy is acyclic.
On top of that, we have also implemented a domain specific language for CHRs together with a basic CHR solver in Haskell.
The most important observation is that we have presented a framework for resolving overloading without having concrete knowledge about the structure of a predicate.
This ensures that multiple compilers can use this framework.
