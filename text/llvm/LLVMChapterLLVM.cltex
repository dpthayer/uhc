%%[chapter
\chapter{LLVM}
\label{cha:llvm}
In the introductory chapter of this thesis, the Low Level Virtual Machine (LLVM) assembly language is mentioned as the typed assembly language that is used as backend target. The LLVM assembly language is part of the LLVM compiler infrastructure project, an free and open source project to implement a compiler backend infrastructure. This chapter discusses 2 elements of the LLVM compiler infrastructure: the life long optimization compilation strategy (\refS{sec:llvm-life-long-optimization}) and the LLVM assembly language (\refS{sec:llvm-assembly-language}).

\section{Why LLVM as backend target}
We choose LLVM over many other typed assembly languages, such as GCCs GIMPLE and C{-}{-}. We believe that LLVM is very attractive as EHC backend target, due to the following reasons:
\begin{itemize}
  \item The executables generated by the Essential Haskell Compiler (EHC) are too inefficient for production quality when compared to executables produced by the Glasgow Haskell Compiler (GHC). LLVM provides aggressive intraprocedural and interprocedural optimizations, which are expected to improve the efficiency of the EHC executables.
  \item For a production compiler, it is important that it can produce executables for many architectures. LLVM supports the X86, X86-64, PowerPC 32/64, ARM, Thumb, IA-64, Alpha, SPARC, MIPS and CellSPU architectures. Initially EHC supports the X86, X86-64 and PowerPC architectures, but the other architectures may be supported later.
  \item The LLVM project has a large user base and is actively maintained. This is an important selection criteria, as architectures and operating systems develop too. It would be a shame if we have a fast Haskell compiler that is unusable because LLVM is not supported on a new architecture or operating system. 
\end{itemize}

\section{Life long optimization}
\label{sec:llvm-life-long-optimization}
Many modern computer applications support dynamic extensions and upgrades. As a result, the behaviour of the applications is likely to change during the lifetime of the application, leading to a change in the spread of execution time in the application. For optimal performance, optimizations must be applied again on the new application code. The life long optimization strategy of the LLVM project aims at providing optimizations for dynamic applications.

The life long optimization strategy consists of 5 parts:
\begin{enumerate}
  \item At compile time, a selection of intraprocedural optimizations are performed on each LLVM assembly module. This allows for separate compilation and fast re-compilations. The selection is extendable, but contains many standard optimizations as dead code elimination, constant propagation, and common sub-expression elimination. The result of this phase is an intraprocedural optimized LLVM assembly module.
  \item Because most code is available for the first time during link time, aggressive interprocedural optimizations are applied then. As during compile time, the selection of optimizations is extendable and LLVM already supplies most well known optimizations. After link time, all LLVM assembly modules are combined in one big optimized LLVM assembly module.
  \item At install time, the characteristics of the architecture are known. During install time, machine dependent optimizations are performed. Good examples are aligning loads and stores, branch reordering, and allocating registers efficiently. The result of the phase is native code. When using static offline code generation, this translates to an native executable. If just-in-time (JIT) compilation is used, install time is during run time and native code is stored for execution by the JIT compiler.
  \item Run time optimizations are only performed when the linked LLVM assembly module is executed via a JIT compiler. The JIT compiler profiles the program and when it detects a hot path during run-time, it applies aggressive run-time optimizations such as specialization on this path.
  \item During runs of the application, there is an opportunity to optimize the program even more. This idle time optimization, or profile guided optimization, optimizes the program with information gathered from profiling information gathered from runs and thus optimizes the program on the behaviour of the user. The profiling information is used to optimise the native executable in a similar way as the JIT engine does during run time. In the current version of LLVM, version 2.3, the idle time optimizer is not available and thus this part of the strategy is not applicable when compiling.
\end{enumerate}

A crucial aspect of this strategy is the persistence of the LLVM assembly language. During the whole life time of the program, the LLVM assembly language is available for optimizing. There are three forms of the LLVM assembly language, which are all isomorphic: the textual form, the bitcode form and bitcode embedded in the native executable.

For EHC, we generate static executables offline, thus optimizing during compile-, link- and install time.

\section{LLVM Assembly Language}
\label{sec:llvm-assembly-language}
\begin{itemize}
  \item Abstracts over machine properties
  \item RISC, 
  \item SSA, and why?
  \item Typed assembly language
  \item Constructs in the LLVM language.
  \item Example C <-> LLVM
\end{itemize}

%%]
