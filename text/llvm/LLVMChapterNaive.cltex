%%[chapter
\chapter{Implementation}
\label{cha:implementation}
In the previous chapters we discussed the generation of Silly (\refS{sec:ehc-silly}). In order to generate executables from Silly code, a backend that outputs Low Level Virtual Machine (LLVM) assembly is added to EHC. In this chapter, we discuss how we generate LLVM from Silly and how it fits into EHC. In particular, we look at the representation of closures in the generated code (\refS{sec:impl-memory-representation}), the transformation from Silly to LLVM assembly (\refS{sec:impl-silly2llvm}), and the runtime system used (\refS{sec:impl-rts}).  

\section{Representation of closures}
\label{sec:impl-memory-representation}
The representation of closures influences typing and generation of LLVM assembly code. The GRIN language uses nodes to represent closures. A node consists of a set of fields, whereas the first field always is a tag and the rest are payload fields. For EHC variant 8, the variant used for the examples through this thesis, possible values of the payload fields are literal integers or pointers to other nodes. Fields may also contain characters, pointers to C strings and floating point values, but this is only the case for other variants than EHC variant 8 used as the starting point for LLVM incorporation.

We represent nodes in memory in a uniform way, no matter which type of values are stored in the payload: a node consists of one or more GrWords. A GrWord is an integer with exactly the same bitsize as a pointer on a architecture and is comparable to the C99 type \texttt{intptr\_t}. This allows us to store any possible tag or payload value in one GrWord. For example, on a 64 bit platform, a GrWord is a 64 bit integer. On this platform, a cons node consisting of a tag, an integer and a pointer to the next list node, is 3 GrWords (or 24 bytes) in size. On a 32 bit platform, where a GrWord is 32 bits in size, the same Cons node would take up 12 bytes.

The uniform representation wastes memory when storing a value which fits in less memory, but allows easy typing of the Silly program (see \refS{sec:impl-typing}) and makes overwriting a closure with its evaluation result type correct.

\section{Transforming Silly to LLVM assembly}
\label{sec:impl-silly2llvm}
The generation of LLVM assembly is divided in two separate tasks: 1) inferring types for Silly variables, values, and constants and 2) tranforming a Silly program to a LLVM program by selecting the correct LLVM instructions. Both tasks are performed simultaneously during transformation from Silly to LLVM.

\subsection{Typing Silly}
\label{sec:impl-typing}
Early in the EHC pipeline, types occuring in a program are erased and subsequent intermediate representations are implicitly typed. LLVM assembly is a strongly typed language, therefore, we need to infer LLVM types from the Silly program.

\begin{figure}[htbp]
	\hsbox{
		\begin{code}
			data LLVMType
			  =  LLVMInt Int
			  |  Pointer LLVMType
			  |  Array Int LLVMType
			  |  Label
			  |  Void
		\end{code}
	}
	\caption{Data type for LLVM assembly types.}
	\label{fig:data-llvm-types}  
\end{figure}

We encode LLVM types by a Haskell data type, shown in \refF{fig:data-llvm-types}. LLVMTypes are a subset of LLVM assembly types because not all LLVM types are needed. Thus we type Silly constructs with LLVM types. The |LLVMInt| constructor corresponds to an integer value of some bit size. The |Pointer| constructor represents a pointer to another |LLVMType|, allowing any level of indirection, although currently a maximum of two levels is used in the generated code. We use C syntax for pointers (postfix \texttt{*}) to abbreviate the |Pointer| construct. The |Array| constructor corresponds to an array of the size of the first parameter. Array types are only used to type C strings. |Label| refers to a branch target and |Void| encodes the absence of a type.

The |LLVMInt| constructor is platform dependent, differing in bit size for architectures with different pointer sizes. To describe the type inference of Silly in a platform neutral way, we use |GrWord| as an alias for a |LLVMInt| constructor where the parameter is the bit size of a native pointer on the architecture.

Each Silly statement can be typed without contextual information like a typing environment. This is possible due to the following assumptions made in Silly:
\begin{itemize}
  \item Global variables are of the type |GrWord**|. Staticly, a block of memory of the size of a native pointer is allocated. In this block, a pointer to a dynamically allocated global closure is stored. This scheme is inefficient, as the global closure could be allocated statically because the size and content are known at compile time. Still the performance loss is small, as the total allocation for global variables is very small compared to the allocations for function local closures.
  \item Local variables are of the type |GrWord*|. A local variable is implemented as a |GrWord| of memory allocated on the stack. Local variables are used for storage of tags, integers, and pointers to closures. If a pointer is stored in a local variable, it needs to be cast to a integer first, without loss of precision. When a pointer is read from the local variable, it needs to be cast back to a pointer.
  \item Function arguments are of the type |GrWord| and the function is responsible for casting a parameter to a |GrWord*| if needed. For functions generated by the compiler, each parameter is always a pointer to a closure (|GrWord*|), whereas parameters of foreign functions often require unboxed values. 

The choice to pass all parameters as |GrWord| types is because of an option in  Silly to manage its own call stack (note: this option is disabled when generating LLVM code). The Silly call stack is defined in the runtime system as an array of |GrWord| elements. Function parameters have the |GrWord| type to avoid casts when pushing function arguments on the stack.  

  \item Function calls can be either a statement or a value. The statement function call is used for calling other Silly functions. These functions have the return type |Void|, as they return values in the global RP array (\refS{sec:ehc-silly}.

Value function calls are calls to foreign functions. These functions do use the C calling convention and return a non-void value. The type of the return value is always a |GrWord|.
  \item Allocations are handled as a foreign function and return a pointer to the allocated memory cast to the |GrWord| type.
  \item Constant integers and tags are of the type |GrWord|.
\end{itemize}

For any semanticly correct abstract syntax tree of a Silly statement, each leaf of the tree matches with one of the above cases. Each other element in the tree is typable with the types of its children and knowledge about the construct itself. An example of this process is shown in \refF{fig:silly-type-example} where we type the  values, variables and constants of the statement \inlCode{C}{i4 := foreign call primSubInt(x78, p1[1]);}. This statement assigns the return value of the primSubInt call to the local variable $i4$. The first parameter of the foreign function call is the local variable $x78$, whereas the second parameter is the first (zero indexed) field of parameter $p1$ .In \refF{fig:silly-type-example} we show the abstract syntax tree of the statement in black boxes and the synthesized type attribute $\tau$ in blue circles.

\begin{figure}[tbhp]
  \begin{centering}
    \input{Silly_type_example.tex}
    \caption{Bottom-up typing of \inlCode{C}{i4 := foreign call primSubInt( x78, p1[1] );} }
    \label{fig:silly-type-example}
  \end{centering}
\end{figure}

We start the typing traversal in the left most leaf of the abstract syntax tree, the local variable $i4$. Each possible leaf value is a base case, thus we are able to deduce the type of the local variable from the known assumptions. Indeed, itÂ´s type is listed as |GrWord*|. 

The second leaf of the abstract syntax tree is the local variable $x78$. Again, local variables always have the type |GrWord*| and thus this value is given to the synthesized attribute $\tau$ of this node. The parent of the leaf is a 'Variable Value' node, which has the semantics of fetching the value where a pointer points to. It infers its type by removing a pointer indirection of the type of its child. This results in a |GrWord| value.

The last leaf of the tree is the parameter variable $p1$. Parameters to functions are passed as a |GrWord|, making this the type of the leaf node. The parent of the leaf node is an array indexing operator, selecting the first field of its child node. For the first time, a type mismatch occurs. The indexing operator expects a pointer type as type of the child, while the child is of the type |GrWord|. The generated code for the indexing operator coerces the type of the child by interpreting the value of the child as an pointer. On this coerced argument indexing is performed and a pointer to the first field is returned, resulting in a value of the |GrWord*| type. When traversing up from the array index node, we encounter a 'Variable Value' node, which de-references the pointer and therefore the type |GrWord| is assigned to $\tau$. 

Finally, the call node is easily typed, as foreign function calls always return a value of the |GrWord| type. This concludes the typing of all values, variables and constructors of this example statement. 

The bottom-up type inferring algorithm is very suitable for an attribute grammar implementation and we implemented it using the Utrecht University Attribute Grammar compiler~\cite{baars:04}, a preprocessor for Haskell.

\subsection{Generation of LLVM}
\label{sec:impl-gen-llvm}

\todo{
\begin{itemize}
  \item LLVM Assembly generation
        \begin{itemize}
          \item Translating Silly to LLVM, example
          \item Expanding to multiple lines of LLVM, LLVMVar attribute, LLVMCode attribute.
        \end{itemize}
\end{itemize}
}

\section{The Run-time System}
\label{sec:impl-rts}
Run-time systems offer services for the running Haskell program. Examples of such services are garbage collection, primitive functions, dynamic loading and dynamic compilation API's. The run-time system of the naive backend offers just enough service to successful run a Haskell program: primitive functions and garbage collection. In this section we describe the design and implementation of the system and elaborate on the choices made.
  
\subsection{Implementation}
\begin{figure}[tb]
  \begin{center}
    \includegraphics[scale=0.7]{rts_structure.png}
  \end{center}
  \caption{The structure of the run-time system}
  \label{fig:rts-structure}  
\end{figure}
\refF{fig:rts-structure} describes the architecture of the run-time system. On the top level, we have multiple source files that define and export functions. These functions are compiled by the a compiler that can compile the source language to object files. The object files are combined in a library, to which the compiled Haskell code can link to, resulting in an executable. Although the current system is entirely implemented in C, the architecture allows us to write specific parts in an other language. This is illustrated in \refF{fig:rts-structure} by the dashed C++ and Haskell (HS) files. We are only restricted by calling convention (in our implementation the C calling convention) and marshalling data between the languages. Furthermore, this architecture allows us to use one run-time system for the C and the LLVM backend.

The design offers advantages, but also some disadvantages. The system fails to provide a clean interface for the Haskell program. This is a drawback for the naive backend, because in LLVM code external functions must be declared. Thus, each run-time function that is used, must be either declared in the Haskell code or inserted by the compiler. Both options are used, as the primitive functions are declared in the prelude and the garbage collection functions are added by the Silly-to-LLVM transformation. Another problem is that the code of the run-time functions are not exposed to the LLVM compiler chain. The LLVM tools are not able to inline the run-time functions and can not analyze the code. This makes the usage of often used functions like allocation more expensive than necessary.

\subsubsection{Interaction between the run-time system and Haskell}
The services of the run-time system are available because they use a common calling convention. But calling functions is only useful if there is a way for the program and the run-time system to interact. We distinguish three different values that could be passed between the program and the run-time:

\begin{enumerate}
  \item Basic values, values that can be considered primitive such as integers, floats and pointers.
  \item Tag values, an unsigned integer that is unique for each constructor in the program.  
  \item Possible unevaluated nodes, a closure consisting of a tag and the payload.
\end{enumerate}

Pure functions that accept basic values as parameters and returns a basic value (e.g. a function that multiplies two integers) work flawlessly. Most of the run-time system consists of such functions. The types are declared in the Haskell code and thus the heap-points-to analysis\todo{ref HPT} can use this information for analyzing values returned by these functions. Because the heap-points-to analysis is directed only by the type of run-time functions, impure functions can break the analysis and break the generated code.

\begin{figure}[tb]
  \begin{lstlisting}[style={figureLst}, language={C}]
#define CFalse 2
#define CTrue 3
  
GrWord primGtInt(GrWord x, GrWord y)
{   
  if (x>y)
  { 
    return CTrue;
  }
  return CFalse;
} 
  \end{lstlisting}
  \caption{Primitive function |primGtInt| from the run-time system}
  \label{lst:primGtInt}  
\end{figure}

Run-time functions that accept or return tag values are a special case of the functions that accept or return basic values. It is obvious that both the run-time system and the compiled Haskell program must share the same mapping between constructors and their tag values. The current implementation of this mapping can be seen in \refF{lst:primGtInt}. The unsigned integer values of the tags |CFalse| and |CTrue| are hard-coded in the run-time system (line 1 and 2) and the same is done in the compiler for these tags. The mappings of these tags are synchronized by hand and are subject of possible synchronisation errors in the future.

The final class of run-time functions, functions that receive nodes as parameter or return nodes, are more problematic than the above cases. When a function has a node as parameter, it may be evaluated or unevaluated. A run-time function could inspect the tag of the node to determine if the node is in weak head normal form. If it is unevaluated, evaluating it with an non inlined |eval| function is an option, but makes the function impure, breaking the heaps-points-to analysis. Evaluating the arguments of runtime functions in advance solves this problem, but makes the functions more strict than they need to be. Creating a node in the run-time system and returning it to the Haskell world is problematic. The heaps-points-to analysis is unaware of this closure and this can result in missing arms in generated |eval| and |apply| functions. Currently we avoid creating closures in the run-time system, but it is desirable for later versions.

\subsubsection{Synopsis}
The current implementation of the run-time system is small, reasonable efficient, and able to support the execution of Haskell programs. Future versions need to focus on efficiency and the interaction between the run-time system and the program.    

\subsection{Garbage Collection}
The initial implementation allocated closures but did not worry about de-allocation. This scheme works for the smallest toy examples, but fills the memory quickly with garbage closures for a more elaborate example. Real Haskell programs depend on a garbage collector to de-allocate obsolete closures that fill the heap.

The naive backend utilizes the Boehm-Demers-Weiser garbage collector~\cite{boehm88gc-c}, a conservative collector designed to work in an uncooperative environment. Conservative collectors do not need support from the language to perform their job. These collectors traverse the stack and interpret each value as a pointer. The values that these pointers point to, are recursively inspected for pointers to values. Each value that can be reached this way from the stack is considered live and thus not garbage. This makes garbage collection very easy to integrate in our backend. \refF{lst:llvm-gc-file} contains all code needed to plug in the garbage collection in the backend. It defines three wrapper functions that wrap C macro functions, because there is no way to call a C macro function in LLVM as they are replaced by their definition at link-time. By replacing the calls from |malloc| to |llvmgc_malloc| and linking in the garbage collection library, we add the collector to the backend.

\begin{figure}[tb]
  \begin{lstlisting}[style={figureLst}, language={C}]
#include <inttypes.h>
#include "gc.h"
/* Init the garbage collector */
void llvmgc_init()
{
  GC_INIT();
}
/* Malloc nBytes */
void* llvmgc_malloc( size_t nBytes )
{
  return GC_MALLOC( nBytes );
}
/* Allocate nBytes and add them to the garbage collection roots */
void* llvmgc_malloc_uncollectable( size_t nBytes )
{
  return GC_MALLOC_UNCOLLECTABLE( nBytes );
}
  \end{lstlisting}
  \caption{The garbage collection run-time interface}
  \label{lst:llvm-gc-file}  
\end{figure}

The generality of conservative garbage collection is also a disadvantage. Conservative collectors lack the information if a value is a pointer and can only do an educated guess. Although this is safe, it can result in memory leaks, leaving garbage uncollected. Precise garbage collectors, collectors that rely on pointer identification information provided by the compiler, do not have this drawback. 

Another inefficiency of conservative garbage collection rises because the implementation does not abstracts over memory, instead it only abstracts over memory management. A great amount of closures on the heap have a short life-time. When the collector frees the memory used by a closure that became unreachable, it leaves the memory fragmented. When this happens often, we use more chunks of memory than needed because of the fragmentation. This problem is often solved by copying collectors, which compact the heap by copying the live memory to a shadow heap. Copying changes addresses of objects, requiring an update of references to objects that were copied. This excludes conservative collectors, because wrong guesses are no longer safe when the value is updated with a pointer value.

We conclude that the current conservative garbage collection is not the most efficient one, but is very easy to integrate. The garbage collector is a likely target for replacement in the future, but for the naive backend it is sufficient.

\comment{

\subsection{Generating LLVM assembly code}
The structure of the LLVM assembly language and Silly is fairly similar, making it an option to write a pretty printer for the transformation. Although this is a simple approach, it also limits us to the textual representation of LLVM assembly. For this reason, we transform the Silly AST to a LLVM AST and pretty print the latter one.

The Silly to LLVM transformation consists of two steps. First the Silly constructs are translated to an equivalent sequence of LLVM constructs. This translation is straightforward as most have a direct counterpart. The second step adds glue code to combine the generated LLVM code with the synthesized LLVM code from the children nodes. This glue code is needed because some conversions are implicit in Silly. For example, assigning a variable to another variable. The variable at the left hand side is interpreted as a location, while the variable at the right hand side is a value. Still, the abstract syntax for a variable is equal at both sides of the equal sign. These conversions must be explicit in LLVM code and thus a cast is added in the generated code if the variable at the left hand side is not a pointer.

\begin{figure}[tb]
	\hsbox{
		\begin{code}
		ATTR  SilModule                              [ ^^ | ^^ |  llvmCode  :  LLVMModule      ]
		ATTR  Function                               [ ^^ | ^^ |  llvmCode  :  LLVMFunction    ]
		ATTR  Statement Alternative Value Variable   [ ^^ | ^^ |  llvmCode  :  LLVMStatements  ]
		ATTR  Value Variable Constant                [ ^^ | ^^ |  llvmVar   :  LLVMVar         ]
		\end{code}
    }
    \caption{Attributes for LLVM Assembly generation.}
	\label{fig:to-llvm-attributes}  
\end{figure}

Because the Silly to LLVM transformation is a bottom-up tree traversal, it is convenient for an attribute grammar implementation. We implemented the transformation using the Utrecht University Attribute Grammar~\cite{baars:04}, a preprocessor for Haskell. The two main attributes are shown in \refF{fig:to-llvm-attributes}. The synthesized attribute |llvmCode| assembles the bottom-up generated |LLVMModule|. Different levels of the Silly AST generate their LLVM counterparts. Values and variables are an exception to this rule as they synthesize LLVM statements. This is  related to the second attribute, |llvmVar|, which is only defined on values, variables and constants. The attribute |llvmVar| is defined as the variable which holds the result of the synthesized |llvmCode|. Generation of the attributes of a Silly node with one or more expressions as children is performed as follows:
\begin{enumerate}
	\item Inspect the synthesized |llvmVar| attributes of the children and check if they are correctly typed. If not, generate a statement in which the synthesized |llvmVar| is cast to the correct type and assign this to a fresh local variable of the correct type.
	\item Construct a chain of one or more expressions that performs the required actions on the results of the previous step. These expressions are assigned to fresh variables.
    \item The |llvmVar| synthesized by this node is the final fresh variable generated in step 2. The new |llvmCode| is the concatenation of the |llvmCode| attributes from the children and the statements generated by step 1 and 2.
\end{enumerate}



}
%%]