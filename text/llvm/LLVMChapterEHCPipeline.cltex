%%[chapter
\chapter{EHC}
\todo{Silly code check}
\label{cha:ehc}
Code generation is only one task that a compiler must perform. Other tasks are parsing, type-checking, and implementing a full fledged compiler is out of scope of the project. We choose the Essential Haskell Compiler (EHC) project as the compiler in which we embed a Low Level Virtual Machine(LLVM) assembly code generator, because EHC is designed to be extended (see \refS{sec:ehc-extending}). The code generator is placed at the tail end of the compiler pipeline, generating code based on output of previous stages. The EHC frontend targets the Graph Reduction Intermediate Notation~\cite{boquist:99} (GRIN) instead of the well known Spineless Tagless G-machine~\cite{jones:92} (STG) model to avoid indirect jumps in the generated code and the overhead introduced by laziness. This choice influences the generated code heavily. In this chapter, we discuss the EHC compiler pipeline stages (\refS{sec:ehc-pipeline}) by showing the intermediate representations from the pipeline stages, and the transformations performed by them.

\section{Extending EHC}
\label{sec:ehc-extending}
The EHC project consists of a sequence of compilers. The first compiler of the sequence, called variant 1, is a compiler for the explicitly typed lambda calculus. The successor of variant 1, not surprisingly called variant 2, extends the compiler by adding type inference. Variant 3 extends variant 2 by adding polymorphism. The sequence of compilers continues until all features of the Haskell language and some extentsions are implemented in variant 100. This design allows us to experiment in a experimental environment, by choosing a compiler which supports a subset of Haskell. More information about the design and implementation of the EHC is available in \cite{fokker:07}.

For this thesis, 2 variants are important:
\begin{itemize}
  \item Variant 8 is the first variant that introduces code generation. The input of variant 8 is limited to Haskell code that operates on abstract data types, |Int| types and |Bool| types. Typical programs compilable by this compiler are programs that operate on lists and |Int| types, for example |sum [1..10]|.
  \item Variant 9 adds two important features on top of variant 8: the class system and the |String| data type. The class system is handled by the frontend, but it complicates the generated code heavily as it adds implicit parameters and coercion code to functions. This in contrast to efficient |String| support, which requires minor additions in the code generator and has minor impact on the complexity of the generated code.
\end{itemize}

\section{The EHC Pipeline}
\label{sec:ehc-pipeline}
A compilation process can be modeled as a pipeline. The start of the pipeline is the input of the source program and the final stage is the produced executable. In between are intermediate representations of the program. The EHC pipeline is shown in \refF{fig:ehc-pipeline} and has the following stages:

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.95\textwidth]{ehc-pipeline}
  \caption{Data flow in the EHC pipeline.}
  \label{fig:ehc-pipeline}
\end{figure}

\begin{enumerate}
  \item First, the Haskell input parsed and desugared to \emph{Essential Haskell}. Essential Haskell was the original input language of EHC and is still accepted by the compiler as input language for experimentation.
  \item The Essential Haskell code is type inferred and if found type correct, transformed to \emph{Core}. The Core language is a lambda calculus with some extensions, where expressions are lambda lifted and type classes are translated to dictionaries. In contrast to several other Haskell compilers' intermediate languages, such as the Glasgow Haskell Compilers (GHC) Core~\cite{tolmach} and Henk~\cite{jones:97}, the EHC Core language is not typed. This is due to practical reasons, as a transformation on typed code implies a transformation on types.
  \item \emph{GRIN} is the first intermediate representation that is part of the EHC backend. The language is a untyped first order strict functional language that makes the sequential order of a Haskell program explicit. In contrast to STG, GRIN uses the eval/apply model~\cite{marlow:04}. Together with closure tagging, it reduces the amount of costly indirect jumps~\cite{fog:07}~\cite{marlow:07} in the generated code. EHC includes a GRIN interpreter to execute the program.
  \item The Simple imperative language (\emph{Silly}) represents programs in a more imperative form. It includes assignments, statements and expressions. The purpose of Silly is to act as a foundation for further translations to imperative languages.
  \item Silly constructs map directly on C. A resulting C program is compiled with an external C compiler and produces a native executable. 
\end{enumerate}

The LLVM Assembly language benefits from the preparations performed by Silly, thus we embed the LLVM code generator after Silly in the pipeline. The external LLVM Assembly compiler then compiles the program to a native executable.

In the following sections, we discuss the Core~(\refS{sec:ehc-core}), GRIN~(\refS{sec:ehc-grin}), and Silly~(\refS{sec:ehc-silly}) phases in more detail because they heavily influence the code generated by the LLVM code generator. Please note that we aim to give enough information of each language to understand the generated code and not describe the languages in detail.  

\subsection{Running Example}
In this chapter, we illustrate the EHC pipeline by threading the program shown in \refF{fig:fib-hs} through the pipeline. The program computes the 33$^{th}$ Fibonacci number (3,524,578) in an inefficient direct recursive translation. The example is small and uses only simple arithmetic on |Int| data types and thus qualifies for the EHC version 8 compiler. This keeps the generated code free from details in the code generated for features supported by higher versions of EHC.

\begin{figure}[htbp]
	\hsbox{
%include build/llvm/Fib.lhs
    }
	\caption{The Haskell source for computing a Fibonacci number.}
	\label{fig:fib-hs}
\end{figure}

\subsection{The EHC Frontend: Essential Haskell and Core}
\label{sec:ehc-core}
\begin{figure}[htbp]
  \lstinputlisting[style={figureLstFootnote}, language={[Core]Haskell}]{FibExe.core}
  \caption{The Core code for the Haskell program of \refF{fig:fib-hs}}
  \label{fig:fib-core}
\end{figure}
We discuss the first two stages of the EHC pipeline, Essential Haskell and Core, in the EHC frontend together. The focus of the frontend is on the features of the Haskell language whereas the focus of the backend is on generating efficient code. Typical tasks of the frontend are parsing, desugaring, lambda lifting, and type checking. 

The frontend produces the Core code that is shown in \refF{fig:fib-core} for the Haskell input from \refF{fig:fib-hs}. The 5 lines of Haskell explode to 59 lines of Core code. The explosion is caused by the explicit inclusion of mathematical operators, the generation of constructor functions and the desugaring from guards to case statements. Although the code is quite verbose, it still resembles the Haskell input, but with some differences:

\begin{itemize}
  \item All top level functions are transformed to a nested let expression. This let expression evaluates to the value of the variable \$main if the module is executable. Version 20 of EHC provides a module system and thus modules without a main function are compiled. The Core code for these non-executable modules contains just the bindings declared in the module.
  \item There are 4 types of bindings in a let expression. Lazy, non recursive bindings are unannotated, while groups of mutually recursive bindings are marked by the keyword 'rec'. Bindings for foreign functions are annotated with the 'foreign' keyword. This distinction of foreign functions is needed later in the pipeline, as parameters to these functions are evaluated before passed to the foreign function. Finally strict let bindings are annotated with a '!'. The strictness annotation is currently only used for forcing the evaluation of the scrutinee in case expressions butis of more general use. For example a strictness analysis can use the annotation to force evaluation of some expressions.
  \item Data constructors are explicitly bound to functions as is shown with the bindings for \$True and \$False. These functions are needed because EHC data constructors cannot be applied partially. By encapsulating data constructing in functions, the regular currying mechanism is used to partially apply data constructors. In the code shown in this chapter, the bindings are not needed, as both constructors have arity 0. EHC relies on optimizations further down the pipeline to remove the dead code.
  \item Types are only available for data constructors and foreign functions. The pipeline stages that follow have to be untyped or re-type the program.
\end{itemize}

\subsection{GRIN}
\label{sec:ehc-grin}
The GRIN language is the first intermediate language of the EHC backend. Boquist~\cite{boquist:99} developed GRIN as alternative for the STG, the backend language adopted by GHC. The main difference between the two models is the strategy for evaluating closures. In GHC the STG language evaluates closures by jumping to the evaluation code in the info table of the closure. After a closure is evaluated, the evaluation code is overwritten with code that returns directly. This strategy is elegant, as suspended functions and evaluated values are treated equal. A disadvantage of the strategy is the performance of the generated code. The object code contains many branches to staticly unknown targets because the address of closures and thus their evaluation code is not known staticly. These so called indirect branches are very inefficient on modern superscalar processors as an indirect branch confuses the branch predictor.

With GRIN, the use of indirect branches in generated object code is eliminated. In the eval / apply model employed by GRIN, a huge case expression evaluates a closure by scrutinizing the tag of the closure. The tag of the closure determines which evaluation code, if needed, is executed. By itself, this does not eliminate indirect branches, as big case expressions are often faster implemented with a jump table instead of a sequence of conditional branches. Combined with inlining of case statements and elimination of unreachable branches, the amount of branches are often reduced enough that a jump table can be omitted.

The GRIN language is a small language and only has a few expressions and one combinator for creating sequences. In contrast with the source language Haskell, GRIN is an impure functional language making functional low level constructs explicit. The impure expressions of the language are store, fetch, and update, all of which put and retrieve nodes to and from the heap. The pure expressions in GRIN are function calls, case expressions, and the unit expressions. Unit expressions can be seen as an monadic return. The value of the unit expression is the value of the node to it.

\begin{figure}[htbp]
  \lstinputlisting[style={figureLstFootnote}, language={grin}]{FibExe.grin}
  \caption{The GRIN code for the Haskell program of \refF{fig:fib-hs}}
  \label{fig:fib-grin}
\end{figure}

GRIN expressions are combined with the sequence combinator. The syntax of the sequence combinator shows resemblance with the monadic bind (|>>=|) in Haskell, but the semantics are more like an imperative assignment operator. A sequence is of the form \inlCode{grin}{\$expr1; \$pat1 -> \$expr2}. This results in the assignment of \$expr1 to \$pat1 in the same way a scrutinee of a haskell case expression is bound to a pattern. Variables in the pattern are bound to the corresponding values of the expression and concrete tags in the pattern are checked against the value of the expression. After the binding, the sequence combinator returns the value of \$expr2, which can use the bindings defined in \$pat1.

\subsubsection{Assumptions of the GRIN language}
The GRIN language makes some assumptions about the structure of the code. These assumptions are not forced by the abstract syntax of the program, but breaking the assumptions leads to incorrect generated code.
\begin{enumerate}
  \item GRIN assumes a closed world. The success of the eval / apply model depends on the possibility to eliminate unreachable branches of inlined evaluation code. In order to eliminate unreachable branches, it must be known which tags are possible for the closure that is evaluated. A heap points to analysis is used to provide this information. This analysis is only accurate if it is able to analyze the full program.
  \item The GRIN program must be in static single assignment (SSA) form. The heap points to analysis gives better results if no aliasing occurs in the program. Also most optimizations perform better if variables are not aliased. In order force this, the whole GRIN program is required to be in static single assignment (SSA) form.
  \item Foreign functions are breaking the closed world assumption of GRIN. This is safe when the foreign functions are pure. Foreign functions are not allowed to modify or return closures, as the behaviour of the foreign function is outside the heap points to analysis.
  \item Arguments passed to GRIN functions are always pointers and the return value must be a node evaluated to weak head normal form. Functions are responsible for parameters and return values and need to evaluate them if needed.
\end{enumerate}

\subsubsection{Generated GRIN code}
\refF{fig:fib-grin} shows the GRIN code generated for the Haskell program  shown in \refF{fig:fib-hs}, before any GRIN transformation is applied. This code is a straight forward translation from the Core code shown earlier (\refF{fig:fib-core}). There are several code conventions for the GRIN code:
\begin{enumerate}
  \item There are different types of variables in GRIN; pointers, nodes, literals and tags. Pointers point to nodes that are stored on the heap, they are not allowed to point to other variables. A node is a set of fields, whereas the first field is always a tag. The following fields, also known as the payload of the node, contain either literals or pointers to other nodes. In the example, the variable name shows the type of the variable. Variables that contain nodes are prefixed with '\$n', pointers with '\$p', literal integers with '\$i', and tags with '\$t'.

The types described above are conceptual; the backend is free to erase the difference between the types and represent everything in an equal way. This is exactly what happens in the EHCs GRIN byte code interpreter, where all GRIN types are represented in a uniform way. Ofcourse, this eliminates possible optimization options based on the difference of the types. 
  \item There are 3 type of nodes in GRIN; constructed values, suspended functions and partial applications. In this example, tags for constructed values are prefixed with an 'C', e.g. CInt, CTrue. The tag prefix for suspended functions is 'F', resulting in tags as Ffib and FprimSubInt. Finally there are partial applied functions. Their tags are prefixed with an 'P'; these are not required for the fib example.
  \item When a pattern match defines bindings that are never used, the variable is replaced by an underscore.
\end{enumerate}

In the generated GRIN code one function is not a direct mapping from the Core code. The \$eval function is responsible for evaluating closures to weak-head normal form. The function consists of a big case expressions with an arm for each possible closure type. The arms for constructed values and partially applied functions just return the node passed to the eval function because they are already in weak-head normal form. More interesting is the code in the arms for suspended functions. The code evaluates the suspended function via a function call and than updates the node with the value returned from it.
Although the eval function is shown in the code in \refF{fig:fib-grin}, in reality it is never generated in this form. Actual generation of the full eval function is a waste of time, as the eval function is inlined at each occurrence; it is included in the example for this explanation.

\begin{figure}[tbhp]
  \begin{centering}
    \input{GRIN_Fib_Tree.tex}
    \caption{A tree of closures as build by the \$fib function of \refF{fig:fib-grin}}
    \label{fig:fib-grin-tree}
  \end{centering}
\end{figure}

GRIN is the first language of the EHC pipeline which makes the creation and order of evaluation of closures explicit. A good example of the generated evaluation order can be seen in the function \$fib. The two equality tests for the base cases are implemented by creating a suspended function call to \$primEqInt and directly evaluating it. If both tests return false, \$fib enters the recursive branch. This translates to GRIN code that creates a closure for each sub-expression in the Haskell expression |fib(n-1) + fib(n-2)|, resulting in the tree of closures illustrated by \refF{fig:fib-grin-tree}. Directly after creating the tree, it is evaluated to weak-head normal form with a call to \$eval. Because the tree is not in weak-head normal form initially, there is a suspended function node at the root of the tree, the evaluation of the tree will result in a call to \$primAddInt. The function \$primAddInt is strict in both arguments because it calls \$eval on both parameters. First, the parameter pointing to the left sub-tree is evaluated, which is a suspended \$fib function. This results in a tree equal to the top level evaluation of \$fib. The unfolding continuous until a base case of \$fib is hit; then the fully unfolded sub-tree is folded again to an integer node. The right sub-tree is evaluated in the same way as the left sub-tree. When both sub-trees are evaluated and reduced to an integer node, the addition of both integers is performed and the program exits after printing the computed value.

The code generated for the three primitive functions illustrates how EHC interfaces with foreign functions. The arguments of the function are evaluated before the call and reduced to a native type. For example, the CInt nodes that are returned by the \$eval function are reduced to a bare machine register integer by selecting the integer field from the node. After each parameter is untagged, the foreign function is called. The return value of the foreign function is either a tag (see \$primEqInt) or an untagged value (see \$primAddInt and \$primSubInt). Tag values can be returned as tag if the node has no payload, while unboxed values need to be wrapped before returned. The code is simplified with regards to the annotations attached to foreign calls. The annotations provide information to the compiler about the marshalling of data from and to the foreign functions. This subject is out of the scope of this thesis.    

\subsubsection{GRIN optimizations}
The code shown in \refF{fig:fib-grin} is very naive. Complete nodes are fetched even though only the tag is needed; small functions are not inlined. Suspended functions are allocated immediately followed by their evaluation instead of being called directly. This is a design choice in GRIN, easily generate naive code followed by applying small and simple optimizing transformations. The static single assignment form of the GRIN program makes optimization easier. The program can then be analyzed without worrying about alias problems.

The effect of the optimization transformations performed by EHC is illustrated by \refF{fig:fib-grin-opt}. It shows the code generated for the recursive branch of the \$fib function. The function \$primAddInt is inlined in this branch and this gives the opportunity to eliminate the allocation of the suspended function nodes FprimAddInt node and Ffib because they are evaluated later in this branch. Furthermore it shows that the closures for the constant nodes (CInt 1) and (CInt 2) are lifted to global variables. This avoids allocating these constants on the heap constantly and allows the function to use the address of the global variable instead. \refF{fig:fib-grin-tree} shows the closures build by the optimized code. The memory allocation by fib is reduced with 65\%.

\begin{figure}[htbp]
  \lstinputlisting[style={figureLstFootnote}, language={grin}]{FibExe-opt.grin}
  \caption{Optimized GRIN code for the recursive branch of \refF{fig:fib-hs}.}
  \label{fig:fib-grin-opt}
\end{figure}

\begin{figure}[tbhp]
  \begin{centering}
    \input{GRIN_Fib_Tree_Opt.tex}
    \caption{Closures build by the optimized version of \$fib}
    \label{fig:fib-grin-tree-opt}
  \end{centering}
\end{figure}

\subsection{Silly}
\label{sec:ehc-silly}
The next step in the EHC pipeline is the Silly language. Silly is the first language that abandons the functional syntax and has a imperative look and feel. The goal of Silly is to abstract over the translation of GRIN to an imperative programming language that is used for the generation of executables. The language contains of basic statements as assignments, switch statements and if-then-else statements. The expressions in the language can be either function calls, variables, constants, and comparisons. All these constructs have a direct counterpart in most well-known imperative languages, such as C and Java.

The translation of GRIN to Silly again removes abstractions and makes the code more concrete. In order to do so, it performs the following transformations and optimizations:
\begin{itemize}
  \item In GRIN code, updating closures is hidden behind the update expression. It was left unspecified whether an update means updating the closure with a new node or with a redirection to a fresh allocated node. Silly allocates enough memory for a closure to store each possible evaluation result of the closure. This strategy allows updates to overwrite the values of the evaluated closure and thus can be reduced to simple assignments to the fields of the closure.
  \item Each function is annotated with the property if it tail calls or not.
  \item A Constant Applicative Form (CAF) is a top level function without parameters. The lack of parameters implies that each closure created for a CAF is equal and evaluates to the same value. To reduce the amount of allocations and optimize the application of CAFs, Silly creates global variable which points to a closure for the CAF. Each application of the CAF uses this closure and thus it is evaluated and updated only once.
  \item Local variables are made explicit in Silly. Local variables are introduced for values that are given different values in arms of an switch statement and for caching a field fetched from a node. Silly optimizes local variables by looking whether a variable is used more than once. If it is, it is assigned to a local variable, else it is inlined. Local variables are declared at the start of each function, so it is known how much memory needs to be allocated at the start of the function.
  \item Often allocations are expensive. The allocator has to search for free space and overhead is added by prepending an allocated block with administration bytes. Silly divides the overhead over all node allocations in a basic block by allocating all needed memory in one allocation request. This results in a significant speed-up, as functional programs tend to allocate many closures. As a draw back of this approach, closures cannot be deallocated separately from each other.
  \item To accommodate for target languages that do not support tail calling natively, the generation of an explicit stack is an option in Silly. Local variables and return addresses are stored on this stack. Indeed, this option is used to generate tail calls for the C code generation backend. For the generation of LLVM code, we disable this option and use the C stack, as LLVM Assembly natively supports tail calling.
  \item Returning nodes from functions is explicit in Silly by assigning to the global node RP, specially used for this purpose. The RP node is large enough to contain each possible node that can be returned and is allocated at the beginning of the program, at the same time the global nodes for CAFs are initialized. This allows target languages without support for multiple return values to return nodes. 
\end{itemize} 

\begin{figure}[hbtp]
  \lstinputlisting[style={figureLstFootnote}, language={C}]{FibExe.sil}
  \caption{Silly code for the recursive branch of \refF{fig:fib-hs}.}
  \label{fig:fib-silly}
\end{figure}

The Silly code generated for the recursive branch of fib is shown in \refF{fig:fib-silly}. The annotation of the function (between curly brackets) shows that the function is a regular function and does not tail call. The function header is followed by the declaration of local variables. Most variables are inherited from the GRIN variables and use the same naming standard. Thus the variables which are prefixed with 'p' stores a pointer to a node, while a 't' refers to a tag, and 'i' refers to an untagged integer. Local variables prefixed with an 'x' are added during the transformation of GRIN to Silly and contain arbitrary types of values.

The creation of a closure in Silly consists of a sequence of allocating memory for all closures and assigning values to the fields. In the example code, 2 closures are created: 2 closures of 3 heap cells for a suspended call to primSubInt, equivalent with the GRIN code shown in \refF{fig:fib-grin-opt}. The allocation request is annotated to be managed by the garbage collector. This annotation can be safely ignored by the code generator, for example if its memory management does not use garbage collection.

The example code also shows some optimizations performed by the Silly language. After the first recursive call to fib, the value of RP[1] is stored in a local variable. This is needed because the second recursive call to fib overwrites the RP node with the node it returns. The return value of the second recursive call to fib is not clobbered by another function call before it is used as parameter of primAddInt. Therefor the assignment to a local variable is omitted and the return value is inlined.  

\section{Synopsis}
This chapter demonstrated the EHC pipeline. Each stage in the pipeline introduced a small language in which an abstraction of the input is removed and gives rise to different optimizations. The input of the pipeline was a simple Haskell program and the result was a Silly program with explicit allocations, assignments and an explicit construction for multiple return values.  

The language Silly is the predecessor for the new stage that we add to the EHC pipeline. The output of the stage is LLVM assembly language, discussed in \refC{cha:llvm}, which is compiled to an executable. The translation from Silly to LLVM Assembly is discussed in \refC{cha:implementation}. 
%%]
