%%[abstract
Haskell's class system provides a programmer with a mechanism to implicitly pass parameters to a function.
A class predicate over some type variable in the type signature of a function induces the obligation to implicitly
pass an appropriate instance of the class to the function.
The class system is programmed by providing class instances for concrete types,
thus providing a unique mapping from types to instances.
This mapping is used whenever an instance for a class predicate over some type is required.
Choosing which instance to pass is solely based on the instantiated type of the class predicate.
Although this mechanism has proved to be powerful enough for modelling overloading and
a plethora of other programming language concepts,
it is still limited in the sense that multiple instances for a type cannot be defined.
Usually one can program around this limitation by introducing dummy types which act as a key to map to additional instances,
but this indirect way of allowing extra instances clutters a program and still is bound to
the finite number of types statically available in a program.
The latter restriction makes it impossible to dynamically construct instances,
which, for example, depend on runtime program input.
In this paper we lift these restrictions by means of local instances.
Local instances allow us to shadow existing instances by new ones and to construct
instances inside functions, using function arguments.
We provide a translation of class and instance definitions to constraint handling rules,
making explicit the notion of ``scope of an instance'' and its role in context reduction for instances.
%%]

%%[introduction
%%@TopicExplImpl.bodyIntro1

These definitions are used by the class system whenever the use of a value requires a class predicate to be satisfied.
For example, the expression |f 3 4| requires |Eq Int| to hold,
satisfied by the instance declaration for |Eq Int|.
Additionally, an evidence based translation implicitly passes a dictionary
for each predicate occurring in the type of the function: |f 3 4| translates to |f eqDInt 3 4|.

For the purpose of \thispaper, the key design choices of this mechanism are:

\begin{itemize}
\item The class system chooses which instance is used to satisfy a predicate, and consequently which dictionary to pass implicitly.
\item The class system makes its choice based on the type(s) over which a class predicate ranges.
\item The only way a programmer can steer the class system is by providing class and instance declarations.
\end{itemize}

These design choices have led to, often ingenious, type level programming and class system extensions to support this,
most notably multiparameter type classes and functional dependencies.
However, the basic mechanism of type based choice of an instance remains the same.
For some programming problems this can lead to contrived code.
For example, suppose we need to compare two |Int|'s modulo 2 and still want to use the class system:

%%@TopicExplImpl.instanceEqIntMod2

How do we instruct the class system to use this instance declaration instead of the previous, default, one?
We can't, at least not without modifying the class |Eq| and its instances.
Although both instances satisfy the predicate |Eq Int|, we have to choose between two dictionaries,
without a means of making the choice: we have overlapping instances.
We can avoid this by changing the classes and instances for |Eq| in such a way that enough additional type
information is provided to make this choice:

%%@TopicExplImpl.instanceEqIntWithExtraType

The price we pay for this flexibility is cluttered and incompatible code,
and one has to plan in advance for such disambiguation.
One can choose to live with cluttered code, but one cannot live with incompatible code because yet established code,
like libraries,
is unlikely to be adapted accordingly.

Instead we propose to use scoped, or local, instances:

%%[[wrap=code
f' p q =  let  instance Eq Int where
                 x == y = primEqInt (x `mod` 2) (y `mod` 2)
          in   f p q
%%]]

Function |f'| invokes |f| within the context of an overriding instance for |Eq Int|.
The static nesting structure of |let| expressions provides the additional information for the class system
to choose between the default |Eq Int| instance at the global level, and the local |`mod` 2| based |Eq Int| instance.

This approach also allows us to tackle the so-called configuration problem \cite{kiselyov04impl-config}
more directly.
Configuration means the parameterization of code with additional data,
without this being visible in the form of additional parameters in the configured code.
For our example this would mean that we would want to test for equality |`mod` n| for arbitrary |n| instead of fixed |`mod` 2|:

%%[[wrap=code
f' n p q =  let  instance Eq Int where
                   x == y = primEqInt (x `mod` n) (y `mod` n)
            in   f p q
%%]]

Besides our first two objections against type based solutions for additional instances, that is clutteredness and incompatibility,
this example points to a third objection: a Haskell program is a closed world with respect to
instances because the set of types is statically determined,
hence the instances indexed by types too.
Scoped instances allow us to take a runtime input value and turn this into an instance, thus configuring the program at runtime.

%%]

%%[problem
Although the idea of scoped (or local) instances already exists for some time
and is available in a limited form known as ``implicit parameters'' \cite{lewis00implicit-param},
to our knowledge scoped instances are neither available nor described previously.
We can see the following areas where the interaction with scope is problematic:
\begin{itemize}
\item Principal typing.
\item The location in the program where the need to prove a predicate arises.
\item Instances requiring other instances as their context.
\item Interaction with type signatures.
\end{itemize}

\Paragraph{Principal typing}
Wadler observed \cite{wadler88how-ad-hoc-poly} that allowing the following program led to loss of principal typing:

%%[[wrap=code
f =  let  instance Eq Int
          instance Eq Char
     in   (==)
%%]]

In his type system he could derive either |f :: Int -> Int -> Bool| or |f :: Char -> Char -> Bool| because of the presence
of the two instances, but not |f :: Eq a => a -> a -> Bool|.
The instantiation of the type of |(==) :: Eq a => a -> a -> Bool|
combined with the satisfaction of the instantiated predicate |Eq a| by either |Eq Int| or |Eq Char| leads to his possible derivations.
However, |(==)| does not even use the corresponding dictionaries, so this interaction seems unnecessary and artificial.
Part of the problem lies with
a check for satisfiability when the type of a value is established, usually as part of a generalization step for |let| bindings.
Such a check also conflicts with modularity because later additional instances may be defined,
and therefore is usually omitted.
Even for the following variant the two instances play no role and could well have been omitted:

%%[[wrap=code
f x y =  let  instance Eq Int
              instance Eq Char
         in   x == y
%%]]

However, the key observation is that as soon as a polymorphic type is instantiated with a more concrete type, and the necessity
to satisfy a predicate over this type arises, such local instances play a role:

%%[[wrap=code
f x y =  let  instance Eq Int       -- now used!
         in   x == y && x == 3
%%]]

In '|x == y && x == 3|'\footnote{We ignore the fact that 3 also gives rise to a |Num| predicate.}
the need for |Eq Int| arises within the scope of the local |Eq Int| instance, and its satisfaction
thus must take the presence of this instance into account.
In terms of a solution for scoped instances, this means that the obligation to prove a predicate like |Eq Int|,
has to be annotated with the scope in which that happens.

\Paragraph{Location}
The above observation complicates matters, as demonstrated by the following example:

%%[[wrap=code
f x =  let  g y =  let  instance Eq Int     ^
                   in   x == y              -- (*)
       in   g 3
%%]]

We only get to know the type of |y| together with |f|'s parameter |x|,
which means that context reduction for the |Eq| predicate
over that type arising at (*) has to be done together with context reduction for |f|,
on a more global level.
The proving machinery then still has to know about the local instance declaration.

\Paragraph{Instances with context}

The combination of instances requiring other instances in their context, overlapping instances,
and local instances makes it rather difficult to predict what combination of instances is used to
satisfy |Show [[[v1]]]| arising in the following example for some type variable |v1|:

%%[[wrap=code
instance Show Char                          -- dShowChar
instance Show a =>  Show [a]                -- dShowL
instance Show [Char]                        -- dShowCharL

showTable hdr tbl 
  =  let  instance Show a =>  Show [[a]]    -- dShowLL
     in   show (map (\x -> x ++ x) hdr : tbl)

main = showTable ["Name", "DOB"]  [["G", "19830511"]
                                  ,["A", "19830208"]]
%%]]

What is the type of |showTable|, and along which path in \figRef{chr-redGraphShowTable}
do we reduce context, if we do context reduction at all?

%%[[wrap=code
showTable :: Show [[[a]]]  => [[a]] -> [[[a]]] -> [Char]
showTable :: Show [a]      => [[a]] -> [[[a]]] -> [Char]
showTable :: Show a        => [[a]] -> [[[a]]] -> [Char]
%%]]

\FigurePDF{t}{0.55}{redGraphShowTable}{Context reduction for showTable}{chr-redGraphShowTable}

The first type opts for no context reduction at all, whereas the second only uses the local instance |dShowLL|, and
the third has several alternative paths available to arrive at |Show v1|.
From the above problems we conclude the following:

\begin{itemize}
\item The proving machinery, declared instances and predicates all need to be aware of (their) scope.
\item The choice offered by local instances complicates making automatic choices during context reduction.
\end{itemize}

\Paragraph{Type signatures}

The role of type signatures becomes more significant:

%%[[wrap=code
e1 :: Int -> Bool
e1 x = x == 2

e2 :: Eq Int => Int -> Bool
e2 x = x == 2

f x =  let  instance Eq Int
       in   e1 x && e2 x
%%]]

Although currently not allowed
\cite{peytonjones03has98-rev-rep},
the type signature for |e2| means that the decision which |Eq Int| to use is delayed until |e2| is called:
in |f| the local instance is used for |e2|, the global one for |e1|.
The presence of a class predicate in a type signatures for |e2| introduces a scoped instance for the body |e2|.
Without local instances this makes no difference, because only one |Eq Int| is present.
%%]

%%[ourContribution
The awareness of scope and complexity of choice leads us to a solution which does not attempt to do the impossible,
that is making the right choice between instances automatically.
Instead we aim for a design where ultimately the programmer has complete control over which instances are to be used.
In \thispaper\ we therefore propose a three stage process for dealing with making choices for local instances separately:

\begin{Itemize}
\item Translate class and instance declarations to an equivalent Constraint Handling Rule (CHR) representation,
      taking scope into account.
\item Solve constraints using the CHR representation, thereby generating all possible solution alternatives for context reduction.
\item Choose between solution alternatives by means of a separate framework.
\end{Itemize}

We focus on the translation to CHR's and the choice between solution alternatives as we feel that there lies the novelty
of our approach.
We present part of our work in terms of Haskell, much in the spirit of \cite{jones99thih}.
A prototype system has been built [..], more extensively described by van den Geest [..],
and has been integrated into the Essential Haskell (EH) compiler
\blindcite{dijkstra04ehc-web,dijkstra05phd}.

We omit the description of a type system in which our context reduction takes place;
although type inference and context reduction interact,
these are largely separate issues.
Our approach can be part of any standard Hindley-Milner type inference algorithm
\cite{damas82principal-type} or be embedded in more recent type inference algorithms
which already are CHR based \cite{sulzmann98hm-constr,stuckey02theory-overloading}.

In summary, our contribution is:

\begin{Itemize}
\item Model scope for class predicates by means of CHR, and provide a different translation to CHR's as compared to Sulzmann e.a. .
\item Provide a framework for expressing different context reduction strategies.
\item A prototype for the above, integrated in a Haskell compiler.
\end{Itemize}

%%]

%%[startingPointWork
We use the following as the direct starting point for our work,
which is investigated at greater length in \blindcite{geest07cnstr-tycls-ext}:

\begin{itemize}
\item
  CHR's \cite{fruhwirth98theory-chr} as used by Sulzmann e.a. \cite{sulzmann98hm-constr,stuckey02theory-overloading}
  to describe and formalize Haskell's type system.
  Our use of CHR's for the class system is slightly different because we postpone any decisionmaking for instances to a later stage.
  We also have to be more precise in dealing with type signatures.
  As we focus on the class system exclusively, we ignore the use of CHR's for the type system.
\item
  Techniques for improving type and class error messages are also constraint based
  \cite{heeren05class-direct,heeren05phd-errormsg,heeren05www-helium}.
  Their solution separates solving constraints from using a solution to produce other results, like error messages;
  we use similar techniques to separately deal with choosing between instances.
\item
  We describe part of our work as an executable specification in Haskell, in the spirit of \cite{jones99thih}.
\item
  Design alternatives for a class system, in particular context reduction,
  were explored in \cite{peytonjones97typecl-explore}.
  Our framework for choices between instances allows to express such context reduction alternatives.
\item
  GHC \cite{www04ghc} allows some form of programming the predicate proving machinery by means of pragmas,
  for example for choosing the most specific instance in case of overlapping instances.
\item
  Named instances \cite{kahl01named-instance,scheffczyk01mth-namedinst} allow explicit named reference to instances.
  This is a natural extension for being explicit in the choice between multiple instances,
  also experimented with in \blindcite{dijkstra04ehc-web,dijkstra05phd}.
\end{itemize}

Furthermore, there is a large body of work on type classes
\cite{jones93constr-class,jones00class-fundep,lewis00implicit-param,chakravarty04assoc-tp-class,chakravarty05assoc-ty-syn},
some of which described in terms of CHR's
\cite{sulzmann98hm-constr,stuckey02theory-overloading,stuckey04exist-tycls,sulzmann06tycls-inf-multi-par,sulzmann07fundep-chr}.
Most of these are relatively independent of scoped instances;
we come back to this later (\secRef{sec-chr-relatedwork}).

%%]

%%[termsAndTypes
\Paragraph{Term, types and predicates}

\figRef{chr-locinst-terms-types} shows the standard term and type language we assume for our discussion of scoped instances.
Although the syntax allows nested classes, we inhibit this.
For simplicity we only consider single parameter type classes.
Overbar notation |Vec(x)| denotes sequences of |x|'s.

%{
%format t = sigma
%format pr = pi
%format dsig = "d_{sig}"
%format dval = "d_{val}"
\begin{TabularCenterFigure}{}{Terms and types}{chr-locinst-terms-types}%
%%@AppxNotation.termTableFormat
%%@AppxNotation.exprHeader
%%@AppxNotation.exprBasic
%%@AppxNotation.exprLetVecDecl
%%@AppxNotation.exprLamIdent
%%@AppxNotation.termSeparator
%%@AppxNotation.declHeader
%%@AppxNotation.declBasicTySigma1
%%@AppxNotation.declBasicVal1
%%@AppxNotation.declBasicValTySigma1
%%@AppxNotation.declExplImplBasic1
%%@AppxNotation.termSeparator
%%@AppxNotation.typeHeader
%%@AppxNotation.typeBasicMono
%%@AppxNotation.typeSchemeMono
%%@AppxNotation.termSeparator
%%@AppxNotation.predHeader
%%@AppxNotation.typredBasic1
%%@AppxNotation.termSeparator
%%@AppxNotation.identHeader
%%@AppxNotation.identBasic
\end{TabularCenterFigure}
%}

Entailment on predicates, shown in \figRef{MiscRules.entailn.all}, is standard \cite{jones94phd-qual-types}.

\rulerCmdUse{MiscRules.entailn.all}

\Paragraph{Constraints}

We use two forms of constraint |Cnstr| over some |varpi|:

%%[[wrap=code
Cnstr   ::=     Prove       varpi
        |       Assume      varpi
        |       Reduction   varpi info [varpi1, ... , varpin]
%%]]

A |Prove varpi| constraint means a prove obligation for |varpi|,
an |Assume varpi| means an assumption for |varpi| introduced by a type signature,
and a |Reduction| means a reduction step from |[varpi1, ... , varpin]| to |varpi|.
Depending on the problem at hand, |varpi| instantiates differently.
For our initial solution without scopes |varpi isbydef pred|.
For our solution with scopes |varpi isbydef (pred,scope)|,
more conveniently notated as |predscope|.
A set of constraints is referred to by constraint as well.
The empty set of constraints represents |True|.

A scope |scope| is defined as a sequence of |Int|'s:
%%[[wrap=code
type scope = [Int]
%%]]
Identifiers |{s, t}| are used to denote scopes |scope|.
The |Int| elements of a scope uniquely identify a definition within an enclosing scope.
A scope |s| is more deeply nested when longer.
The common scope of two scopes is defined as their longest common prefix,
which always exists because the global scope always is common.

%%[[wrap=code
commonScope :: scope -> scope -> scope
commonScope (x:xs)  (y:ys)  | x == y     = x : commonScope xs ys
                            | otherwise  = []
commonScope _       _                    = []
%%]]

A scope |s| is visible from a scope |t| if their common scope equals |s|:

%%[[wrap=code
visibleIn :: scope -> scope -> Bool
s `visibleIn` t = s == s `commonScope` t
%%]]

Constraint satisfaction is defined in terms of entailment:
\begin{Definition}[Constraint Satisfaction |solves|]
Let |Theta| be a constraint solution which consists of a set of assumed qualifiers |PiTheta|.
A \emph{Prove} constraints is satisfied if the corresponding qualifier is entailed by the set of assumed qualifiers |PiTheta|.
%%[[wrap=code
Theta solves Prove          varpi                               ^^   isdef     ^^    PiTheta entails ThetaVarpi
Theta solves Assume         varpi                               ^^   isdef     ^^    ThetaVarpi insign PiTheta
Theta solves Reduction      varpi info [varpi1, ... , varpin]   ^^   isdef     ^^    True
%%]]
An \emph{Assume} is satisfied if the assumed qualifier is an element of |PiTheta|.
A \emph{Reduction} is trivially satisfied.
\end{Definition}

\Paragraph{Constraint Handling Rules}

Constraint handling rules (CHR's) \cite{fruhwirth98theory-chr}
are a constraint language for constraint solvers.
A CHR defines a rewrite rule between constraints:

%%[[wrap=code
H1, ... , Hi <==>  G1, ... , Gj ^^ | ^^ B1, ... , Bk      ^^  (simplification)
H1, ... , Hi  ==>  G1, ... , Gj ^^ | ^^ B1, ... , Bk      ^^  (propagation)

(i > 0, j >= 0, k >= 0)
%%]]

The |(H1, ..., Hi)| are the \IxAsDef{head} of a CHR,
the conditions |(G1, ..., Gj)| are the \IxAsDef{guard} of a CHR, and the constraints |(B1, ..., Bk)| are the \IxAsDef{body} of a CHR.
The empty constraint set is abbreviated with |true|.

Operationally, a simplification rule replaces the set of constraints in
the head by the constraints in the body when the conditions in the guard
are satisfied. A propagation rule adds the constraints in the body if
the constraints in the head are present and the conditions in the guards
are satisfied. A propagation rule can be applied infinitely many times,
but we avoid non-termination by applying a propagation rule only once
to every constraint in the constraint set.

CHRs can be given a declarative semantics \cite{fruhwirth98theory-chr}.
A simplification is a logical equivalence if the guards are satisfied:
%%[[wrap=code
forall ^ Vec(x) forall ^ Vec(y)  ((G1 && ... && Gj)
                                 -> (H1 && ... && Hi <--> exists ^ Vec(z) (B1 && ... && Bk))
%%]]
Similarly, a propagation is an implication if the guards are satisfied:
%%[[wrap=code
forall ^ Vec(x) forall ^ Vec(y)  ((G1 && ... && Gj)
                                 -> (H1 && ... && Hi -> exists ^ Vec(z) (B1 && ... && Bk)))
%%]]

%%]

%%[toCHRplain
\Paragraph{Simplication and context reduction}

Suppose we have the following class and instance declarations:
%%[[wrap=code
class Eq  a                ^^   ^^     --   (C1)
class Eq  a   => Ord a     ^^   ^^     --   (C2)
class Ord a   => Real a    ^^   ^^     --   (C3)
instance Eq a => Eq [a]    ^^   ^^     --   (I1)
%%]]

These declarations translate to the following set of (generated) CHR's,
where |varpi isbydef pi| and |pi| is a class predicate:
%%[[wrap=code
Prove(Eq a)    , Prove(Ord a)    <==> Prove(Ord a)    ^^ ^^ -- (C2)
Prove(Ord a)   , Prove(Real a)   <==> Prove(Real a)   ^^ ^^ -- (C3)
Prove(Eq a)    , Prove(Real a)   <==> Prove(Real a)   ^^ ^^ -- (C23)
Prove(Eq [a])                    <==> Prove(Eq a)     ^^ ^^ -- (I1)
%%]]

When applied to the constraint set |{Prove(Eq [v1]),| |Prove(Ord v1),| |Prove(Real v1)}|
we obtain the following derivation:

%%[[wrap=code
          ^^  {Prove(Eq [v1])  , Prove(Ord v1), Prove(Real v1)}
deriv(I1) ^^  {Prove(Eq v1)    , Prove(Ord v1), Prove(Real v1)}
deriv(C2) ^^  {Prove(Ord v1)   , Prove(Real v1)}
deriv(C3) ^^  {Prove(Real v1)}
%%]]

All rules but (C23) directly correspond to a class or instance declaration.
In order to guarantee confluence it is necessary to have the
transitive closure of the class hierarchy available in rule form.
To see why, suppose rule (C23) is not available,
then the following derivation also is possible:

%%[[wrap=code
          ^^  {Prove(Eq [v1])  , Prove(Ord v1), Prove(Real v1)}
deriv(C3) ^^  {Prove(Eq [v1])  , Prove(Real v1)}
deriv(I1) ^^  {Prove(Eq v1)    , Prove(Real v1)}
%%]]

The final set of constraints differs unless we can use rule (C23).

\Paragraph{Interaction with type inference}

The constraint set |{Prove(Eq [v1]),| |Prove(Ord v1),| |Prove(Real v1)}|
typically would arise from a program fragment like the following:

%%[[wrap=code
f (x:xs)  =   xs  ==  []                    --  Prove(Eq [v1])
          &&  x   <   1                     --  Prove(Ord v1)
          &&  const True (toRational x)     --  Prove(Real v1)
%%]]

Constraint solving would be done for |f|'s binding group, after all information about |v1| would have been
reconstructed.
Constraint solving then leaves us with an unsatisfied |Prove(Real v1)|,
which we only can satisfy if we have a corresponding assumption |Assume(Real v1)| and the following rule:

%%[[wrap=code
Prove p, Assume p <==> Assume p ^^ ^^ -- (E)
%%]]

We do know we can assume |Real v1| either because

\begin{itemize}
\item
  The type inferencer decides it can generalize over class predicate |Real v1| and reconstruct the following type for |f|:
%%[[wrap=code
f :: Real a => [a] -> Bool
%%]]
  In that case unresolved |Prove| constraints lead to corresponding |Assume| constraints,
  and constraint solving can proceed with these |Assume| constraints.
\item
  Or the programmer has provided the type signature:
%%[[wrap=code
f :: Real a => [a] -> Bool
%%]]
  In that case the type signature directly leads to a constraint |Assume(Real c1)| for some fixed type variable |c1|,
  and the body yields |{Prove(Eq [c1]),| |Prove(Ord c1),| |Prove(Real c1)}|.
\end{itemize}

Note that here we differ from the `standard' CHR \cite{stuckey02theory-overloading} way of dealing with type signatures
by encoding their entailment check as rule (E) combined with a richer constraint language which includes |Assume|.
We also assume that the type inferencer is capable of using a type signature in such a way that fixed type variables introduced
by the signature end up in |Prove| constraints via their binding from program variables;
this usually is accomplished by some form of bi-directional type inference and type checking combination
\cite{peytonjones04pract-inf-rank,vytiniotis06boxy-impred,dijkstra05phd}.
Furthermore, we need this explicitness for assumptions when dealing with scopes and alternate entailment solutions.

\Paragraph{Type signatures}

Suppose we have a simpler version of |f|:

%%[[wrap=code
f (x:xs)  =   xs  ==  []                    --  Prove(Eq [v1])
%%]]

This would lead to the following inferred type for |f|:

%%[[wrap=code
f :: Eq a => [a] -> Bool
%%]]

However, providing the following type signature would leave us with unresolved constraints unless we add class hierarchy
induced rules for |Assume|
constraints  as well:

%%[[wrap=code
f :: Real a => [a] -> Bool
%%]]

We now get stuck at |{Prove(Eq c1),| |Assume(Real c1)}| because there are no rules to end up with |{Prove(Eq c1),| |Assume(Eq c1)}|.
We have to add propagation rules for |Assume| constraints corresponding to the class hierarchy:

%%[[wrap=code
Assume(Ord a)    ==> Assume(Eq a)  ^^ ^^  -- (CA2)
Assume(Real a)   ==> Assume(Ord a) ^^ ^^  -- (CA3)
%%]]

The derivation for |{Prove(Eq c1),| |Assume(Real c1)}| can then proceed:

%%[[wrap=code
           ^^   {Prove(Eq c1), Assume(Real c1)}
deriv(CA3) ^^   {Prove(Eq c1), Assume(Real c1), Assume(Ord c1)}
deriv(CA2) ^^   {Prove(Eq c1), Assume(Real c1)
                , Assume(Ord c1), Assume(Eq c1)}
deriv(E)   ^^   {Assume(Real c1), Assume(Ord c1), Assume(Eq c1)}
%%]]

\Paragraph{Overlapping instances: simplification versus propagation rules}

Uptil now we have used simplification rules for instance declarations: 

%%[[wrap=code
Prove(Eq [a])                    <==> Prove(Eq a)     ^^ ^^ -- (I1)
%%]]

Operationally this means that a CHR solver replaces the prove requirement for |Prove(Eq [a])|
with a prove requirement for |Prove(Eq a)|.
However, in the presence of overlapping instances we loose confluency:

%%[[wrap=code
instance Eq a => Eq [a]    ^^   ^^     --   (I1)
instance Eq [Int]          ^^   ^^     --   (I2)
%%]]

For (I2) we now also have the following rule:

%%[[wrap=code
Prove(Eq [Int])                    <==> True     ^^ ^^ -- (I2)
%%]]

Solving |Prove(Eq [Int])| either leads to |Prove(Eq Int)| (via (I1)) or to |True| (via (I2)).
A solution could be to add guards \cite{stuckey02theory-overloading}:

%%[[wrap=code
Prove(Eq [a])                   <==> a /= Int | Prove(Eq a)       ^^ ^^ -- (I1)
Prove(Eq [Int])                 <==> True                         ^^ ^^ -- (I2)
%%]]

However, although this indeed inhibits rule (I1) when appropriate,
it requires all instances to be known, checked for their specificness relative
to each other, and guards generated accordingly.
This conflicts with separate compilation and modules
-- GHC therefore inhibits context reduction using instances unless enforced by a type signature --
and
it is unclear how it interacts with more complex type-class extensions.
Furthermore, a simplification rule as above enforces a choice between instances;
this conflicts with our intention to make such choices visible so we can deal with those choices separately.

For these reasons we will avoid simplification rules and use propagations rules instead.
A subtle consequence of this design choice is that the interaction with a constraint solver becomes slightly different
in that entailment does no longer follows from the absence of |Prove| constraints in the final set of solved constraints,
but non-entailment follows from a |Prove| constraint \emph{not} propagated from by any rule.

\Paragraph{Making choice explicit: derivation tracing}

The given rules describe how to solve constraints, but leave no trace of how this is done, do not indicate solution alternatives,
and do not give enough information to proceed with code generation (for example).
We therefore let each rule also generate a |Reduction| constraint, as some form of `side-effect' of a rule,
yielding a derivation trace when solved.
Consider again the following instance declarations:

%%[[wrap=code
instance Eq a => Eq [a]    ^^   ^^     --   (I1, dEqList)
instance Eq [Int]          ^^   ^^     --   (I2, dEqListInt)
%%]]

These instances lead to the following propagation rules:

%%[[wrap=code
Prove(Eq [a])
  ==>  Prove(Eq a)                                            ^^ ^^ -- (I1)
  ,    Reduction (Eq[a]) "dEqList" [Eq a]
Prove(Eq [Int])
  ==>  Reduction (Eq [Unit]) "dEqListInt" []                  ^^ ^^ -- (I2)
%%]]

Solving |Prove(Eq [Int])| now results in the following constraint set:

%%[[wrap=code
{  Prove (Eq[Int])
,  Reduction (Eq[Int]) "dEqList" [Eq Int]
,  Prove(Eq Int)
,  Reduction (Eq[Int]) "dEqListInt" []   }
%%]]

The |info| field of a |Reduction| constraint holds additional (generated) information we need for subsequent
stages.
In the given example we include the program variable of the dictionary for the instance.
We also need different rules for a class hierarchy.
For example, for the following class:

%%[[wrap=code
class (Eq a, Show a) => Num a
%%]]

we generate the following CHR's, where the |info| field of a |Reduction| now refers to the field of the dictionary
holding the superclass dictionary:

%%[[wrap=code
Assume(Num a)
  ==>  Assume(Eq    a)
  ,    Reduction (Eq    a) "eqOfNum"     [Num a]
  ,    Assume(Show  a)
  ,    Reduction (Show  a) "showOfNum"   [Num a]
Prove(Eq    a), Prove(Num a)
  ==>  Reduction (Eq    a) "eqOfNum"     [Num a]
Prove(Show  a), Prove(Num a)
  ==>  Reduction (Show  a) "showOfNum"   [Num a]
%%]]

The reduction steps now tell us whether a class predicate |pi| is entailed;
in the above example |Eq Int| is not entailed because there is no |Reduction| constraint for |Eq Int|.
Before proceeding with the construction of a reduction graph used in choosing alternate reduction paths
in \secRef{sec-chr-heuristics},
we first turn our attention to scoped instances and their CHR representation.

%%]

%%[toCHRscoped
Scoped instances allow us to write:

%%[[wrap=code classEq
class Eq a where
  (==) :: a -> a -> Bool
  
instance Eq Int where                                       ^^ -- (I1)
  x == y = primEqInt x y

v1 =  3 == 5                                                ^^ -- False
v2 =  let  instance Eq Int where                            ^^ -- (I2)
             x == y = primEqInt (x `mod` 2) (y `mod` 2)
      in   7 == 9                                           ^^ -- True
%%]

Both CHR's as well as constraints reduced by those CHR's need to be aware of scope in order to obey the usual static scope rules:
constraints arisen in scope |scope| can only be reduced by CHR's defined in |scope'|, where |scope'| is visible from |scope|.
For example, the global scope in which (I1) is defined is |scope = []|, the scope in which (I2) is defined is |scope = [3]|.
The constraint |Prove (Eq Int)| for expression |3 == 5| arises in scope |[]|, for expression |7 == 9| it arises in scope |[3]|.
For the latter both (I1) and (I2) can be used for context reduction.
This normally means an error because of overlapping instances,
but by using scope information we can distinguish and choose between instances.

We define the scope |scope| of a program location as follows:

\begin{itemize}
\item
  The global scope |scope isbydef []|.
\item
  The body of each |let| introduced binding has scope |scope isbydef scope' ++ [n]|,
  where |n| is a unique |Int| value among all bindings in the surrounding scope |scope'|.
\item
  The body of a lambda expression for which the type signature (if any) specifies class predicates
  has scope |scope isbydef scope' ++ [0]|
  in the surrounding scope |scope'|.
\end{itemize}

The scope of both an instance and an arisen constraint is defined to be the scope of the program location where
the instance is defined respectively a constraint arises.
A class predicate |pi| in a constraint is annotated with this scope |scope|, so |varpi isbydef (pred,scope)|,
alternatively denoted by |predscope|.
The entailment relation is extended (in \figRef{MiscRules.entailscn.all}) with a rule for lifting a scoped class predicate
to a more global scope.
The rule for instances is restricted to apply to predicates of the same scope only.
The class rule still applies to any predicate since classes are only defined globally.
When the scope |scope| is omitted from |predscope|, |pred| ranges over any scope.

\rulerCmdUse{MiscRules.entailscn.all}

The scope rule is non-deterministic: it can be applied anywhere and reduce to any outer or equal scope.
We make the rule deterministic by moving the check for visibility to the instance rule,
see \figRef{MiscRules.entailscn.algo}.
A reduction to scope |t| now only occurs when an instance is defined in scope |t|.
The class rule remains unchanged as classes are global.

\rulerCmdUse{MiscRules.entailscn.algo}

%% \Paragraph{CHR's for instances}

We change the translation of instances to CHR's accordingly, for |instance (pred1, .. , predn) => pred|, in scope |scope|
we get:

%%[[wrap=code
Prove (pred, s)
  ==>  scope `visibleIn` s 
  |    Reduction (pred, s) (ByInstance instName scope) [(pred1, s), .. , (predn, s)]
  ,    Prove (pred1, s), .. , Prove (predn, s)
%%]]

The |Reduction| constraint is annotated with both the name and the scope of the instance;
we come back to |ByInstance| later when this annotation is used to choose between |Reduction|'s.
For our current example we have:

%%[[wrap=code
Prove (Eq Int, s)
  ==>  [] `visibleIn` s 
  |    Reduction (Eq Int, s) (ByInstance "I1" []) []
Prove (Eq Int, s)
  ==>  [3] `visibleIn` s 
  |    Reduction (Eq Int, s) (ByInstance "I2" [3]) []
%%]]

and the following derivation for |Prove (Eq Int, [3])| arising at |7 == 9|:

%%[[wrap=code
          ^^  {Prove (Eq Int, [3])}
deriv(I1) ^^  {Prove (Eq Int, [3])
              , Reduction (Eq Int, [3]) (ByInstance "I1" []) []}
deriv(I2) ^^  {Prove (Eq Int, [3])
              , Reduction (Eq Int, [3]) (ByInstance "I1" []) []
              , Reduction (Eq Int, [3]) (ByInstance "I2" [3]) []}
%%]]

where the |Reduction|'s in the final constraint set correspond to the graph in \figRef{chr-redGraphEqIntTwice}.
We still have overlapping instances, but we are now ready and prepared for making the choice.
In \secRef{sec-chr-refinements} we refine the translation to CHR's to avoid too much scope related clutter in the
final set of |Reduction| constraints.

\FigurePDF{t}{0.55}{redGraphEqIntTwice}{Context reduction for scoped Eq Int}{chr-redGraphEqIntTwice}

%% \Paragraph{CHR's for classes}


%%]

%%[heuristics
Starting with the final set of constraints a CHR solver leaves us with, we do the following:
\begin{itemize}
\item We extract all |Reduction| constraints.
\item From these |Reduction| constraints we construct a reduction graph such as in \figRef{chr-redGraphEqIntTwice}.
\item From the reduction graph we construct all possible alternative reductions.
\item From alternative reductions we choose heuristically.
\item From the chosen reduction we generate evidence, that is, a representation of the code required for constructing dictionaries.
\end{itemize}

We use the following, contrived running example, where \figRef{chr-redGraphEqOrdListTup} shows the reduction graph for |f|:

%%[[wrap=code
instance Eq Int                      -- dEqInt  
instance Eq a => Eq [a]              -- dEqL    
instance (Eq a,Eq b) => Eq (a,b)     -- dEqTup  
instance Ord Int                     -- dOrdInt 
instance Ord a => Ord [a]            -- dOrdL   
instance (Ord a,Ord b) => Ord (a,b)  -- dOrdTup 

f :: Ord a => (a,Int) -> [(a,Int)] -> Bool
f x (y:ys) = x == y && x < y && [x] == ys && [y] < ys
%%]]

\FigurePDF{t}{0.5}{redGraphEqOrdListTup}{Reduction heuristics example}{chr-redGraphEqOrdListTup}

We present these sequence of steps in Haskell.

\Paragraph{Constraints}

From the CHR solver we get the final set of constraints, where constraints are represented as:

%%[[wrap=code
data Constraint varpi info  =  Prove      varpi
                            |  Assume     varpi
                            |  Reduction  varpi info [varpi]
                            deriving (Eq, Ord)
%%]]

\Paragraph{Reduction graph}

From these constraints we construct the reduction graph,
for which we use the inductive graph library \cite{erwig01inductive-graph} to encode an Annotated Graph (|AGraph|)
for nodes |a| and edges |b|
with the following interface:

%%[[wrap=code
emptyAGraph :: Ord a => AGraph a b

insertEdge   :: Ord a =>    (a, a, b)    -> AGraph a b -> AGraph a b
insertEdges  :: Ord a => [  (a, a, b)]   -> AGraph a b -> AGraph a b
deleteEdge   :: Ord a =>    (a, a)       -> AGraph a b -> AGraph a b

successors, predecessors :: Ord a => AGraph a b -> a -> [(b, a)]
%%]]

Nodes are predicates |varpi| from |Constraint|'s, edges are reductions labeled with |info|.
Predicates |varpi| are wrapped in a |Node| so we can represent conjunction:

%%[[wrap=code
data Node varpi  =  Pred varpi
                 |  And [varpi]
                 deriving (Eq, Ord)

instance Show varpi => Show (Node varpi) where
  show (Pred p)    = show p
  show (And [])    = "True"
  show (And _ )    = "And"

true  ::  Node varpi
true  =   And []
%%]]

Disjunction is encoded by multiple outgoing edges in the graph structure.

\Paragraph{Reduction alternatives}

\Paragraph{Choosing heuristically}

\Paragraph{Evidence generation}

%%]

%%[refinements
----------------

Although the rules in \figRef{MiscRules.entailscn.algo} (and omitted rules present in \figRef{MiscRules.entailn.all})
are sufficient for entailment,
they do not provide detailed enough information about when exactly scope related choices are made.
More precisely, the rules do not make explicit when the scope changes take place: use of different scope is hidden inside
the instance rule.
We need this information to be explicit so we can make a choice between 'forgetting scope' and 'using an instance'.
%%]

%%[XX
%%]

%%[XX
%%]

%%[XX
%%]

%%[XX
%%]

%%[XX
%%]

%%[XX
%%]

%%[XX
%%]

