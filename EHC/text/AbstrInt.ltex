\documentclass[preprint,9pt]{sigplanconf}

%include lhs2tex.fmt

\def\spacecorrection{\;}
\def\isspacecorrection{\spacecorrection}
\def\allowforspacecorrection#1{%
  \gdef\temp{#1}%
  \ifx\isspacecorrection\temp
    \let\next=\empty
  \else
    \let\next=\temp
  \fi
  \next}



\newcounter{enumctr}
\newenvironment{enumate}{%
\begin{list}{\arabic{enumctr}}{
\usecounter{enumctr}
\parsep  = 0pt
\parskip = 0pt
\topsep  = 0pt
\itemsep = 0pt
}}{\end{list}}
\newenvironment{itize}%
{\begin{list}%
  {$\bullet$%
  }%
  {\parsep  = 0pt%
   \parskip = 0pt%
   \topsep  = 0pt%
   \itemsep = 0pt%
  }%
}%
{\end{list}%
}



%format GrModule  = "\mathit{Module}"
%format GrGlobalL = "\mathit{GlobalL}"
%format GrGlobal  = "\mathit{Global}"
%format GrBindL   = "\mathit{BindL}"
%format GrBind    = "\mathit{Bind}"
%format GrExpr    = "\mathit{Expr}"
%format GrAltL    = "\mathit{AltL}"
%format GrAlt     = "\mathit{Alt}"
%format GrTermL   = "\mathit{TermL}"
%format GrTerm    = "\mathit{Term}"
%format GrPatAlt  = "\mathit{PatAlt}"
%format GrPatLam  = "\mathit{PatLam}"
%format GrVarL    = "\mathit{VarL}"
%format GrVar     = "\mathit{Var}"
%format GrTag     = "\mathit{Tag}"
%format HsName    = "\mathit{Name}"
%format getNr     = "\mathit{nr}"
%format GrTag_Con     = "\mathit{Tag\_Con}"
%format GrTag_Fun     = "\mathit{Tag\_Fun}"
%format GrTag_PApp    = "\mathit{Tag\_PApp}"
%format GrTag_App     = "\mathit{Tag\_App}"
%format GrTag_Unboxed = "\mathit{Tag\_Unboxed}"
%format GrTag_Any     = "\mathit{Tag\_Any}"

%format DATA = "\mathbf{syntax}"
%format TYPE = "\mathbf{type}"
%format SET  = "\mathbf{set}"
%format ATTR = "\mathbf{attr}"
%format SEM  = "\mathbf{sem}"
%format USE  = "\mathbf{use}"
%format SYN  = "\mathbf{syn}"
%format INH  = "\mathbf{inh}"
%format .    = "."
%format ^    = " "
%format ^^    = "\;"
%format ^@    = "@"
%format LET  = "\mathbf{let}"
%format IN   = "\mathbf{in}"

%format @ = "\spacecorrection @"
%format [          = "[\mskip1.5mu\allowforspacecorrection "
%format (          = "(\allowforspacecorrection "
%subst fromto b e t     = "\fromto{" b "}{" e "}{{}\allowforspacecorrection " t "{}}'n"





\usepackage{amsmath}

\usepackage{natbib}
\bibpunct();A{},
\let\cite=\citep
\bibliographystyle{plainnat}



\begin{document}

\conferenceinfo{ICFP '07}{September 30, Freiburg.} 
\copyrightyear{2007} 
\copyrightdata{[to be supplied]} 

%\titlebanner{Working copy v.1}        % These are ignored unless
%\preprintfooter{Working copy v.1}   % 'preprint' option specified.

\setlength{\parindent}{0pt}
\setlength{\parskip}{3pt}


\title{Abstract Interpretation to Avoid Indirect Jumps}
\subtitle{an Attribute Grammar Approach}

\authorinfo{Jeroen Fokker\and S.~Doaitse Swierstra}
           {Utrecht University}
           {\{jeroen,doaitse\}@@cs.uu.nl}

\maketitle

\begin{abstract}
This is the text of the abstract.
\end{abstract}

%\category{CR-number}{subcategory}{third-level}

%\terms
%term1, term2

%\keywords
%keyword1, keyword2

\section{Introduction}

The text of the paper begins here.


\section{Case selection and Indirect Jumps}






Case distinction is the driving force in lazy languages

Push/enter vs eval/apply

Marlow\&Peyton Jones

Boquist \cite{boquist1996} \cite{boquist1999}

EHC




\section{Tree walk methodology}\label{sec.ag}

\subsection{Ways to define semantics}

% If a single phenomenon needed to be nominated as the
% most fundamental aspect of computer science, it would
% be the ability to generalize from specific instances
% through abstraction and parameterization.
% Every programming language has a way to define 
% subroutines, procedures, functions, methods, or other
% manifestations of abstraction, and to call them with
% appropriate parameters.

Functional languages are famous for their ability to 
parameterize functions not only with numbers and data structures,
but also with functions and operators.
The standard textbook example involves the functions |sum| and |product|,
which can be defined separately by tedious inductive definitions:
\begin{code}
sum      []      = 0
sum      (x:xs)  = x + sum xs
product  []      = 1
product  (x:xs)  = x * product xs
\end{code}
but, once this pattern has been generalized in a function |foldr|
that takes as additional parameters the base value and the operator to apply
in the inductive case:
\begin{code}
foldr op e []      = e
foldr op e (x:xs)  = x `op` foldr op e xs
\end{code}
could easily have been defined as specializations of the general case:
\begin{code}
sum      = foldr (+)  0
product  = foldr (*)  1
\end{code}
Indeed, good generalizations might have unexpected applications in other domains:
\begin{code}
concat     =  foldr (++) []
sort       =  foldr insert []
transpose  =  foldr (zipWith (:)) (repeat [])
\end{code}
The idea that underlies the definition of |foldr|, i.e.\ to capture the pattern
of an inductive definition by adding a function parameter for each constructor of
the data structure, can also be used for other data types, and even for
multiple mutually recursive data types.
Functions that can be expressed in this way were called {\em catamorphisms}
by Bird, and the collective extra parameters to |foldr|-like functions 
an {\em algebra} \cite{bird}. 
Thus, |((+),0)| is an algebra for lists, and |((++),[])| is another.
In fact, every algebra defines a {\em semantics} of the data structure.
When applying |foldr|-like functions to the algebra consisting of the original constructor functions,
such as |((:),[])| for lists, we have the identity function.
Such an algebra is said to define the `initial' semantics.

Outside circles of functional programmers and category theorists, an
algebra is simply known as a `tree walk'.
In compiler construction, algebras could be very useful to define
a semantics of a language, or bluntly said to define tree walks over the parse tree.
The fact that this is not widely done, is due to the following problems:

\begin{enumate}
\item Unlike lists, which have a standard function |foldr|, in a compiler we deal with
      (many) custom data structures to describe the abstract syntax of a language, 
      so we have to invest in writing a custom |fold|
      function first. Morover, whenever we change the abstract syntax,
      we need to change the |fold| function, and every algebra.
\item Data structures for abstract syntax tend to have many alternatives,
      so algebras end up to be clumsy tuples containing dozens of functions.
\item Generated code can be described as a semantics of the language, but often
      we need additional semantices: pretty-printed listings, warning messages,
      and various derived structures for internal use (symbol tables etc.).
      This can be done by having the semantic functions in the algebra return
      tuples, but this makes the algebras even clumsier.
\item In practice, information not only flows bottom-up in the parse tree,
      but also top-down. E.g., symbol tables with global definitions need
      to be distributed to the leafs of the parse tree to be able to evaluate them.
      This can be done by having the semantic functions in the algebra take
      additional parameters, but this pushes handling algebras beyond human control.
\item Much of the work is just passing values up and down the tree.
      The essense of a semantics is sparsely present in the algebra,
      and obscured by lots of boilerplate.
\end{enumate}

Many compiler writers thus end up writing ad hoc recursive functions
instead of defining the semantics by a nice algebra,
or even resort to non-functional techniques.
Others succeed in giving a concise definition of a semantics,
often using proof rules of some kind, but thereby loose the executability.
For the implementation they still need conventional techniques,
and an issue arises whether the program soundly implements
the specified semantics.

To save the nice idea of using an algebra for defining a semantics,
we use a preprocessor for Haskell that overcomes the abovementioned problems \cite{agsyst}.
It is not a separate language; we can still use Haskell for writing
auxiliary functions, and use all abstraction techniques and libraries available.
The preprocessor just allows a few additional constructs, which are translated
into a custom |fold| function and algebras.


\subsection{An Attribute Grammar based preprocessor for Haskell}

We describe the main features of the preprocessor here, and why it overcomes
the five problems mentioned above.
To start with, the abstract syntax of the language is defined in a |DATA| declaration,
which is like a Haskell {\bf data} declaration with named fields.
The difference is that we don't have to write braces and commas,
and that constructor function names need not to be unique.
As an example, we define a fragment of a typical imperative language:
\begin{code}
DATA Stat
  =  Assign  dest   :: String  ^^ ^^  src   :: Expr
  |  While   cond   :: Expr    ^^ ^^  body  :: Stat
  |  Group   elems  :: [Stat]
DATA Expr
  =  Const   num   :: Int
  |  Var     name  :: String
  |  Add     left  :: Expr     ^^ ^^  right  :: Expr
  |  Call    name  :: String   ^^ ^^  args   :: [Expr]
\end{code}
The preprocessor generates corresponding {\bf data} declarations
(making the constructors unique by prepending the type name, like |Expr_Const|),
and more importantly, generates a custom |fold| function. This overcomes problem 1.

For any desired value we wish to compute over a tree, we can declare a `synthesized attribute'.
Attributes can be defined for one or more data types.
For example, we can define that both statements and expressions need to 
synthesize bytecode as well as pretty-printed listing, and that expressions
can be evaluated to an integer value:
\begin{code}
ATTR Expr Stat  SYN bytecode  :: [Instr]
                SYN listing   :: String
ATTR Expr       SYN value     :: Int
\end{code}
The preprocessor will ensure that the semantic functions will return appropriate
tuples, but in our program we can simply refer to the attributes by name.
This overcomes problem 3.

The value of each attribute needs to be defined for 
every constructor of every data type which has the attribute.
As this defines the semantics of the language, these definitions
are known as `semantic rules', and start with keyword |SEM|.
An example is:
\begin{code}
SEM Stat | Assign
  @lhs.listing =  @dest.listing ++ ":=" ++ 
                  @src.listing ++ ";"
\end{code}
This states that the synthesized |listing| attribute
of an assignment statement can be constructed
by combining the |listing| attributes of its |dest| and |src| children
and some fixed strings.
The |@| symbol in this context should be read as `attribute',
not to be confused with Haskell `as-patterns'.
At the left of the |=| symbol, the attribute to be defined is mentioned;
at the right, any Haskell expression can be given.
The |@| symbol may be omitted in the destination attribute,
as is done in the next example. 
This example shows that it is indeed useful that any Haskell expression,
with embedded occurrences of child attributes, can be used in the definition.
Also, it shows that the value of terminal symbols can be used (|@num| in the example),
and that multiple semantic rules can be grouped under a single |SEM| header:
\begin{code}
SEM Stat | While
  lhs.bytecode =  let  k = length @cond.bytecode
                       n = length @body.bytecode
                  in   @cond.bytecode
                       ++ [BEQ (n+1)]
                       ++ @body.bytecode
                       ++ [BRA (-(n+k+2))]
SEM Expr
  | Const  lhs.value = @num
  | Add    lhs.value = @left.value + @right.value
\end{code}
The preprocessor collects and orders all definitions into a single algebra,
replacing the attribute references by suitable selections from the results 
of the recursive tree walk on the children. 
This overcomes problem 2.

To be able to pass information downward during a tree walk,
we can define `inherited' attributes
(the terminology goes back to \cite{knuth}).
As an example, it can be used to pass an environment,
i.e.\ a lookup table that associates variables to values,
which is needed to evaluate expressions:
\begin{code}
TYPE Env = [(String,Int)]
ATTR Expr INH env::Env
SEM Expr | Var
  lhs.value = fromJust (lookup @lhs.env @name)
\end{code}
The value to use for the inherited attributes can be defined
in semantic rules higher up the tree:
\begin{code}
SEM Stat | Assign
  src.env = [ ("x",37), ("y",42) ]
\end{code}
The preprocessor translates inherited attributes into
extra parameters for the semantic functions in the algebra.
This overcomes problem 4.

In the example above, an environment with two variables was just made up.
In reality, a |Stat| construct probably inherited the environment
from even higher constructs, say a procedure declaration.
This means that the only thing that needs to be done at the |Stat| level,
is to pass the inherited environment down to the children.
This can be quite tedious to do:
\begin{code}
SEM Stat
  |  Assign  dest.env  = lhs.env
             src.env   = lhs.env
  |  While   cond.env  = lhs.env
             body.env  = lhs.env
\end{code}
Luckily, the preprocessor has a convention that, 
unless stated otherwise, attributes with the same name
are automatically copied. So, the attribute |env| that
a |Stat| inherited from its parent, is automatically copied
to the children which also inherit an |env|, and the tedious rules
above can be omitted.
A similar automated copying is done for synthesized attributes,
so if they need to be passed unchanged up the tree, this needs
not to be explicitly coded.

When more than one child offers a candidate to be copied,
normally the last one is taken.
But if we wish that a combination of the copy candidates
is to be used, we can specify so in the attribute declaration.
An example is:
\begin{code}
ATTR Expr Stat
  SYN listing USE (++) []
\end{code}
which specifies that by default, the synthesized
attribute |listing| is the concatenation of the |listing|s of
all children that have one, or the empty list if no child has one.
This defines a useful default rule, which can be overridden
when extra symbols need to be interspersed, as for example in
the definition of |listing| for assignment statements given earlier.

It is allowed to define both an inherited and a synthesized attribute
with the same name. In combination with the copying mechanisms,
this enables us to silently thread a value through the entire
tree, updating it when necessary. See section~\ref{sec.collect}
where this is used to maintain, in attribute |location|,
a unique counter during the tree walk.

The preprocessor automatically generates semantic rules
in the standard situations described, and this overcomes problem 5.




\section{The Grin language}\label{sec.lang}

The Grin language (Graph Reduction Intermediate Notation)
was proposed by Boquist as an intermediate language
between the Core language that is used
in Haskell compilers to describe a desugared program,
and an imperative backend \cite{boquist1999}.

We describe a slightly modified version here, which is
more explicit than Boquist's original description
about what constructs are allowable in various places.
Instead of the usual BNF description, we introduce the
language by means of Haskell datatype declarations
(or rather |DATA| declarations for the AG preprocessor).
The advantage of this approach is that this makes explicit
the types and names of child constructs of each nonterminal symbols.
Also it is part of our endeavour to make the description to be
both specification and implementation of the abstract semantics of the language.

The semantics/interpretation that is treated in this paper
is an abstract interpretation needed for analysis of the program.
In the same style we are able to present other semantices.
In our compiler \cite{ehc} we implement a translation to bytecode that
is executable by a simple interpreter, and a translation
to a generic imperative language that can in turn be translated
to various backend languages.

In our presentation of the language we do not provide
a concrete syntax for the language, as normally is implicitly
done in a BNF description.
One reason for this is that a concrete syntax is unnecessary,
as Grin programs are only used as an intermediate representation
in the compilation process, and technically are merely data structures.
Another reason is that the mental parsing and unparsing involved
when reading the semantics description in later sections could
distract the reader from the algorithm proper, and cause confusion
between program fragments as data structures and their semantic values.

We start our description with a definition of toplevel constructs.
A program consists of a single module, which has a name,
a list of global variable definitions, and a list of function bindings.
Note that in our naming, we conventionally use suffix |L| for `list',
and prefix |mb| for `maybe'.
\begin{code}
DATA Program
  = Prog      mod          :: GrModule
DATA GrModule
  = Mod       nm           :: HsName
              globalL      :: GrGlobalL
              bindL        :: GrBindL
TYPE GrGlobalL  =   [GrGlobal]
TYPE GrBindL    =   [GrBind]
\end{code}
A global definition binds a name to a term,
whereas a function binding binds a parameterized name
to an expression.
\begin{code}
DATA GrGlobal
  = Global  nm              :: HsName
            val             :: GrTerm
DATA GrBind
  = Bind    nm              :: HsName
            argNmL          :: [HsName]
            expr            :: GrExpr
\end{code}
Values of five kinds can be manipulated by Grin programs:
integers, nodes with a known tag and a list of fields,
standalone tags, pointers to a node stored on the heap,
and an empty value.
The first three kinds of value have a direct syntactic
representation as a |GrTerm|, pointers and the empty value have not.
Another possible |GrTerm| is a variable, which can refer to any of the five kinds of value.
\begin{code}
DATA GrTerm
  =  LitInt  int    :: Int
  |  Tag     tag    :: GrTag
  |  Node    tag    :: GrTag
             fldL   :: GrTermL
  |  Var     nm     :: HsName
TYPE GrTermL  =  [GrTerm]
\end{code}
Although the syntax above includes nested nodes,
we stipulate that this is not allowed;
if nested nodes are desired, the field list should contain
variables that point to heap cells storing the inner nodes.

Tags are used to label a node.
Six different tags are possible:
\begin{code}
DATA GrTag
  |  Con   nm        :: HsName
  |  Fun   nm        :: HsName
  |  PApp  needs     :: Int
           nm        :: HsName
  |  App
  |  Unboxed
  |  Hole
\end{code}
Best known is the |Con| tag, which is used to label nodes
that build up datastructures in Grin.
They correspond to constructor functions in the Haskell source program,
but unlike constructor functions, nodes with a |Con| tag are always fully saturated.
For implementing lazy evaluation we have a |Fun| tag, which is needed
to construct function `thunks', i.e.\ function applications of which the evaluation is postponed.
Nodes with |Fun| tag are always fully saturated.
If partial parameterization is desired, a |PApp| tag is used instead,
which, apart from the function name, also specifies the nummer of missing 
parameters it still |needs|.

The other three tags are an extension to those proposed by Boquist.
When a lazy call is needed to a function of which the name is not statically known,
a special thunk node is used. It has tag |App|;
the first field of the node represents the function,
the other fields its arguments to which the function is applied when the thunk is forced to evaluate.
The |Unboxed| tag is used as a mockup tag for constructs that conceptually are nodes,
but in reality are implemented as unboxed values.
Finally, there is a |Hole| tag that is used in the implementation of recursive definitions,
but that plays no special role in the analysis described in this paper.

The most ubiquitous construct in a Grin program is an expression.
It is used to represent the body of function bindings.
An expression can be evaluated to a value, during which side effects on the heap may occur.
There are twelve cases in the expression syntax:
\begin{code}
DATA GrExpr
  =  Seq          expr            :: GrExpr
                  pat             :: GrPatLam
                  body            :: GrExpr
  |  Unit         val             :: GrTerm
  |  UpdateUnit   nm              :: HsName
                  val             :: GrTerm
  |  Case         val             :: GrTerm
                  altL            :: GrAltL
  |  FetchNode    nm              :: HsName
  |  FetchUpdate  src             :: HsName
                  dst             :: HsName
  |  FetchField   nm              :: HsName
                  offset          :: Int
                  mbTag           :: Maybe GrTag
  |  Store        val             :: GrTerm
  |  Call         nm              :: HsName
                  argL            :: GrTermL
  |  FFI          nm              :: String
                  argL            :: [HsName]
                  tagL            :: GrTagL
  |  Eval         nm              :: HsName
  |  Apply        nm              :: HsName
                  argL            :: GrTermL
\end{code}
We give an informal description of the semantics of these constructions,
that is their runtime evaluation result and side effects.
A formal description would be a Grin interpreter, which is not the focus of this paper.

An expression |Unit val| simply evaluates to a known value |val|.
Evaluation of expression |Seq expr pat body| first evaluates |expr|,
binds the result to |pat| and in the extended environment evaluates |body|.
Boquist uses a monadic style concrete syntax for this construct:
|expr ; \pat -> body|, which is why we declared |pat| to have type |GrPatLam|
(for `lambda pattern').
It can however just as well be thought of as |LET pat=expr IN body|
or even as an imperative style assignment |pat:=expr; body|.
Concrete syntax is immaterial; what is important is that |expr| and |body|
are evaluated sequentially.

Boquist proposes two constructs which have a side effect on the heap:
|Store|, which stores a node value in a new heap cell and returns a pointer to it,
and |Update|, which stores a node value in an existing heap cell and returns the empty value.
We do have a |Store| expression in our language, 
but instead of a separate |Update| expression we have |UpdateUnit|,
which combines the overwriting of an existing heap cell with returning the value.
This allows for a more efficient implementation of the combination.
Boquist uses a single construct |Fetch| for fetching either a complete node,
or a particular field of a node. Because these two variants behave quite differently,
we have separate constructs |FetchNode| and |FetchField|, and a |FetchUpdate|
which combines fetching a node and use it to update an existing heap cell.

Next, we have a construct |Call| for calling a Grin function,
and |FFI| for calling a foreign function.
Boquist proposes the use of two builtin functions |eval| and |apply|,
which can be called to force evaluation of a variable,
or to force application of an unknown function in a strict context, respectively.
As these functions behave quite different than ordinary functions,
we choose to include special constructs |Eval| and |Apply| for these cases.

Finally, there is a |Case| construct which selects from a list
of alternatives the one that has a pattern that matches 
the value of the variable in the |Case| header (the `scrutinee').
Each alternative consists of a pattern and a corresponding expression:
\begin{code}
DATA GrAlt
  | Alt  pat   :: GrPatAlt
         expr  :: GrExpr
TYPE GrAltL = [GrAlt]
\end{code}
Patterns in a case alternative normally consist of a node
with a known tag, and variables as arguments.
Standalone tags and literal integers are also possible patterns:
\begin{code}
DATA GrPatAlt
  =  LitInt      int             :: Int
  |  Tag         tag             :: GrTag
  |  Node        tag             :: GrTag
                 fldL            :: [HsName]
\end{code}
A pattern in a case alternative is quite different from
a lambda pattern that is used in a |Seq| expression.
A lambda pattern is often just a variable name.
Two other possibilities are |Empty|, to be able to match
for the empty result value of the |FetchUpdate| expression that
only has a side effect, and a node denotation where
the tag can, but needs not be, known:
\begin{code}
DATA GrPatLam
  =  Empty
  |  Var         nm              :: HsName
  |  VarNode     fldL            :: GrVarL
DATA GrVar
  =  Var         nm              :: HsName
  |  KnownTag    tag             :: GrTag
TYPE GrVarL     =   [GrVar]
\end{code}
We assume the existence of a special name
\begin{code}
wildcard :: HsName
\end{code}
that can be used as a wildcard variable name
(`don't care variable') in a lambda pattern.

To complete our exposition of the Grin language, we
define abbreviations for some groups of nonterminal symbols,
which in the next section facilitates the definition
of attributes that are needed for all of them:
\begin{code}
SET AllDef    =  GrGlobal GrGlobalL GrBind GrBindL
SET AllTerm   =  GrTerm GrTermL
SET AllExpr   =  GrExpr GrAlt GrAltL
                 GrPatAlt GrPatLam GrVar GrVarL
\end{code}



\section{Abstract interpretation}

In this section we describe an abstract interpretation
algorithm for Grin programs.
The algorithm solves a set of constraints by doing a
fixpoint iteration.
The constraints are first collected by doing a tree walk
over the Grin program.
We start with a description of an abstract domain,
and a language for specifying the constraints.

\subsection{An abstract domain}

Grin programs consist largely of bindings,
which bind Grin expressions to function names.
Expressions in turn are built from terms,
of which a possible form is a single variable.
Although Grin is an untyped language,
in code generated from a correct Haskell program
variables always refer to values of the same kind:
basic values, nodes, tags, or heap pointers.
We will use abstract interpretation not only 
to infer these kinds, but also to collect more detailed 
information about the runtime structure of values.

When executed, a Grin program maintains a heap of
dynamically allocated nodes.
More specifically, execution of a |Store| expression
allocates a new heap cell, as do |Global| variable definitions.
Our abstract interpretation algorithm will
also determine, for each |Store| expression and
each |Global| definition, what type of node it can create.
The abstraction of all heap cells that a particular
|Store| or |Global| creates is known as a |Location|.
Thus, each |Location| corresponds uniquely to
a |Store| or |Global|. In our implementation we
identify locations simply by consecutive numbers:
\begin{code}
type Location = Int
\end{code}
Grin variables refer to five different
kinds of value:
the empty value,
integers,
standalone tags,
pointers to a heap location,
or complete nodes.

We introduce a data type |AbstractValue| which we use
as an abstract domain for the abstract interpretation.
It distinguishes four cases for the five differet kinds of value (both the empty value and integers are regarded as `basic'), 
with added bottom and error cases to form a complete lattice
suitable for fixpoint iteration.
\begin{code}
data AbstractValue
  =  AbsBottom
  |  AbsBasic
  |  AbsTags   (Set GrTag)
  |  AbsLocs   (Set Location)
  |  AbsNodes  (Map GrTag [AbstractValue])
  |  AbsError  String
\end{code}
In the |AbsTags| case, abstract interpretation will reveal
to which subset of all possible tags a variable can refer.
Similary, for |AbsLocs| we determine to which locations
a pointer can point.
In the |AbsNodes| case, we not only determine the possible
tags of the nodes, but for each of these also a list of the abstract values of their parameters.
In section~\ref{sec.lang} we stipulated that nested nodes are only allowed
by letting the fields be variables which refer to pointers to heap cells storing the inner nodes.
This invariant propagates to |AbsNodes|: the elements of the fields of a node are
never |AbsNodes| themselves, but can be |AbsLocs| pointing to locations which store inner nodes.
  
The fact that |AbstractValue| indeed forms a lattice
is expressed by the following definition,
which specifies how two abstract values can be merged into one.
We state that |AbsBottom| is the identity of a |Monoid|
\begin{code}  
instance Monoid AbstractValue where
    mempty  =  AbsBottom
\end{code}
That is, any abstract value remains unchanged when merging it with |AbsBottom|
\begin{code}
    mappend  a          AbsBottom   =  a
    mappend  AbsBottom  b           =  b
\end{code}
Abstract values of each of the four types can be merged with others of the same type:
\begin{code}
    mappend AbsBasic AbsBasic     
       =  AbsBasic
     mappend (AbsTags  at) (AbsTags  bt) 
       =  AbsTags (Set.union at bt)
     mappend (AbsLocs  al) (AbsLocs  bl) 
       =  AbsLocs (Set.union al bl)
     mappend (AbsNodes an) (AbsNodes bn) 
       =  AbsNodes  (Map.unionWith 
                      (zipWith mappend) an bn)
\end{code}
Errors remain an error even when merged with other values:
\begin{code}
     mappend a^@(AbsError _ ) _  =  a
     mappend _ b^@(AbsError _ )  =  b
\end{code}
And new errors originate from merging abstract values from incompatible types:
\begin{code}
     mappend a b  
       =  AbsError (show a ++ " conflicts " ++ show b)
\end{code}  
  
  
  
  
  
The goal of the abstract interpretation algorithm is
to determine the abstract value of each variable
in the program, and likewise for each abstract heap |Location|.
For efficiency reasons we represent these mappings by arrays:
\begin{code}
type AbstractEnv s  
  =  STArray s Variable AbstractValue
type AbstractHeap s 
  =  STArray s Location AbstractValue
\end{code}
Like a |Location|, each |Variable| is also represented by a number:
\begin{code}
type Variable = Int
\end{code}
A preprocessing stage uniquely numbers all variable names in a program
(taking care of scoping where necessary),
and makes the sequence number available through a function
\begin{code}
getNr :: HsName -> Variable
\end{code}


\subsection{A constraint language}\label{sec.constraintlang}

By observing a Grin program, we can deduce equations
which constrain variables and locations.
Before doing so, we need a language to specify these constraints.
We introduce the type |Equation| for describing six different
types of constraints for the abstract value of variables.
Likewise, we have |HeapEquation| for specifying constraints
on the abstract values of abstract heap locations.
\begin{code}
data Equation
  =  IsKnown          Variable  AbstractValue
  |  IsSuperset       Variable  Variable
  |  IsSelection      Variable  Variable Int GrTag
  |  IsConstruction   Variable  GrTag [Maybe Variable]
  |  IsEvaluation     Variable  Variable
  |  IsApplication    (Maybe Variable) [Variable]
\end{code}
Five out of six equation types constrain a variable to fulfill certain properties.
Only in the case of an |IsApplication| equation, 
the variable that is constrained appears |Maybe|, i.e.\ is optional.

A variable may be constrained by more than one equation.
These equations are cumulative. 
If for example one constraint specifies that a variable `is known'
to have a particular abstract value, 
and another constraint specifies that it is known to have
another value, the abstract interpretation algorithm will
conclude that this variable can refer to either value.


Below we describe informally the semantics of the six equation types.
A formal description is given in figure~\ref{fig.envChanges},
which is discussed in section~\ref{sec.solution}.
First, an equation
|IsKnown v a| means that variable |v| can have abstract value |a|.
The meaning of |IsSuperset v w| is that variable |v| can have all 
values that variable |w| has. 
An |IsSuperset v w| equation should thus be understood as `|v| can have any value that |w| can have'.

The equation |IsSelection v n i t| expresses that |v| can be the 
selection of the |i|th component of any node tagged by |t|
which can be the value of variable |n|.
Dually, the meaning of |IsConstruction v t as| is that |v| can be
a node with tag |t| and arguments |as|. Not all arguments need to be known.

Next, the meaning of |IsEvaluation v w| is that |v| can refer to the
evaluation result of any possible value of |w|.
Finally, the meaning of |IsApplication v (f:as)| is that 
|f| is a variable that refers to a function which is applied to
values referred to by variables |as|,
and that the result is a possible value of |v|.
For this type of constraint, mentioning a variable |v| is optional.
If it is lacking, the equation still bears information
on the possible values of parameters of |f|.

For heap equations, we have only one constraint type:
\begin{code}
data HeapEquation
  =  WillStore Location GrTag [Maybe Variable]
\end{code}
The meaning of |WillStore p t as| is that location |p|
stores a node with tag |t| and arguments |as|.
A heap cell always stores a complete node,
not an isolated value of other type 
(basic value, tag or pointer to another heap cell).

The sets of constraints for variables and locations, respectively,
are simply collected in lists, for which we define the following types:
\begin{code}  
type Equations      = [Equation]
type HeapEquations  = [HeapEquation]
\end{code}



\subsection{Collect constraints in a tree walk}\label{sec.collect}

In this subsection we describe a tree walk over a Grin program
that collects constraints on the program variables that need to hold.
The tree walk is implemented using the attribute grammar (AG) based
language described in section~\ref{sec.ag}, that can be used
as a preprocessor to Haskell.

The goal of the tree walk is to synthesize |equations| stating
the constraints for program variables, and |heapEqs| stating
the constraints for locations (abstract results of store expressions
and global definitions).
\begin{code}
ATTR Program GrModule AllDef AllExpr
  SYN  equations  USE (++) []  :: Equations
  SYN  heapEqs    USE (++) []  :: HeapEquations
\end{code}
The declarations above specify that both type of equations
are not only synthesized for the whole program, but also
the intermediate levels of the program tree that have to do
with definitions and expressions. No equations are synthesized
on the levels that have to do with values and variables.
The |USE| clause in the declaration of the attributes
expresses that the default way to synthesize
equations is just to concatenate the equations synthesized on
underlying levels. We will redefine the |equations| and
|heapEqs| attributes later for the tree positions where
equations are introduced.

But first we require some auxiliary attributes.
First, we need to uniquely number all abstract locations,
as we represent locations by integers.
For this purpose we have both a synthesized and
an inherited attribute |location| for all relevant 
positions in the tree.
With a semantic rule, value 0 is inserted for this
attribute at the top of the tree.
\begin{code}
ATTR Program GrModule AllDef AllExpr
  INH SYN  location  ::  Int
SEM Program | Prog
  mod.location = 0
\end{code}
The AG preprocessor ensures that the inherited attributes are
passed unchanged down the tree, and the synthesized values are passed up,
unless there is a AG rule which specifies that a modified value should
be passed.
Indeed, in figure~\ref{fig.equations} we have rules that increment
the location counter when locations need to be numbered,
viz.\ at |Store| expressions and |Global| definitions.

Before we explain the rest of the rules in figure~\ref{fig.equations},
we need to define an auxiliary datastructure that is
used as the type of some attributes to come.
Nodes sometimes are indirectly referred to by a variable, 
sometimes they are directly enumerated in full.
The following datatype distinguishes these two cases, 
where the polymorphic type variable |a| is the type of additional
information that we may want to express for the parameters of the node.
Function |fromInVar| can be used to retrieve the variable from
a |NodeInfo| that is known to be a |InVar| case.
\begin{code}
data NodeInfo a 
  =  InVar   Variable 
  |  InNode  GrTag [a]
 
fromInVar :: NodeInfo a -> Variable
fromInVar (InVar v)  = v
\end{code}
This datatype is used in attributes |termInfo| and |patInfo|
that summarize whether terms and patterns are denoted indirectly through 
a variable, or directly as a node with tag and fields:
\begin{code}
ATTR  GrTerm    SYN termInfo  :: NodeInfo (Maybe Variable)
ATTR  GrPatAlt 
      GrPatLam  SYN patInfo   :: NodeInfo Variable
\end{code}
Some auxiliary attributes are necessary to make the summary:
\begin{code}
ATTR  GrTerm   SYN  var      :: Maybe Variable
ATTR  GrTermL  SYN  vars     :: [Maybe Variable]
ATTR  GrVar    SYN  tag      :: GrTag
               SYN  var      :: Variable
ATTR  GrVarL   SYN  hdTag    :: GrTag 
               SYN  vars     :: [Variable]
\end{code}
The semantic rules for these attributes are straightforward.
It is described by the following AG rules
(remember that the |SEM| construct specifies semantics,
that is attribute values, for various constructors
of a the datatypes that were introduced in section~\ref{sec.lang}).
\begin{code}
SEM GrTerm
| Tag        lhs.termInfo  =  InNode  @tag []
| Var        lhs.termInfo  =  InVar   (getNr @nm)
| Node       lhs.termInfo  =  InNode  @tag @fldL.vars
SEM GrPatAlt
| Tag        lhs.patInfo   =  InNode  @tag []
| Node       lhs.patInfo   =  InNode  @tag (map getNr @fldL)
SEM GrPatLam
| Empty      lhs.patInfo   =  InVar   wildcard
| Var        lhs.patInfo   =  InVar   (getNr @nm)
| VarNode    lhs.patInfo   =  InNode  (@fldL.hdTag)
                                      (tail @fldL.vars)
SEM GrTerm
| Var        lhs.var       =  Just    (getNr @nm)
| * - Var    lhs.var       =  Nothing
SEM GrTermL
| Cons       lhs.vars      =  @hd.var : @tl.vars
| Nil        lhs.vars      =  []
SEM GrVarL  
| Cons       lhs.hdTag     =  @hd.tag
SEM GrVarL
| Cons       lhs.vars      =  @hd.var : @tl.vars  
| Nil        lhs.vars      =  []
SEM GrVar
| KnownTag   lhs.tag       =  @tag
| Var        lhs.var       =  getNr @nm
\end{code}
The |patInfo| attribute defined above is used
to determine the target of each expression.
For most expressions, the target is the next
pattern in the sequence. For the last expression in a
sequence that is the body of a function, the target
is the function name bound in a |Bind| binding,
and passed all the way through the |Seq| spine.
This is expressed in the semantic rules that specify
the |targetInfo| attribute:
\begin{code}
ATTR AllExpr 
  INH targetInfo :: NodeInfo Variable
SEM GrBind | Bind  
  expr.targetInfo  =  InVar (getNr @nm)
SEM GrExpr | Seq    
  expr.targetInfo  =  @pat.patInfo
  body.targetInfo  =  @lhs.targetInfo
\end{code}
The |termInfo| attribute defined earlier is used in the semantics rules 
for various expression forms in figure~\ref{fig.equations}.
The |termInfo| attribute value synthesized by the scrutinee term
of a |Case| expression is also needed in the alternatives
of that |Case| expression.
It is therefore passed down as an inherited attribute
to the alternatives: 
\begin{code}
ATTR GrAlt GrAltL 
  INH termInfo :: NodeInfo (Maybe Variable)
\end{code}
No explicit semantic rules are needed here, as the AG system automatically
routes the value synthesized by the first child of
a |Case| expression (the scrutinee) as the value
of the inherited attribute with the same name of its second 
child (the list of alternatives).

\begin{figure*}
\begin{code}
SEM GrExpr | Unit UpdateUnit
  loc.equations1   = case (@lhs.targetInfo, @val.termInfo) of
                       (InVar tvar        ,  InVar svar        )  -> [IsSuperset tvar svar]
                       (InVar tvar        ,  InNode stag snms  )  -> [IsConstruction tvar stag snms Nothing]
                       (InNode ttag tnms  ,  InVar svar        )  -> buildSelectEquations svar ttag tnms
                       (InNode ttag tnms  ,  InNode stag snms  )  -> buildUnifyEquations  snms tnms
SEM GrExpr | UpdateUnit
  loc.equations2   =  [ IsSuperset (getNr @nm) (getNr @val.getName) ]
SEM GrExpr | Unit
  lhs.equations    =  @loc.equations1
SEM GrExpr | UpdateUnit
  lhs.equations    =  @loc.equations2 ++ @loc.equations1

SEM GrAlt | Alt  
  lhs.equations    =  case (@pat.patInfo, @lhs.termInfo) of
                        (InNode ttag tnms, InVar svar)  -> buildSelectEquations svar ttag tnms

SEM GrExpr | FetchNode
  lhs.equations    =  case @lhs.targetInfo of
                        InVar tvar  ->  [ IsSuperset  tvar          (getNr @nm)   ]
SEM GrExpr | FetchUpdate                ^             ^             ^             ^
  lhs.equations    =                    [ IsSuperset  (getNr @dst)  (getNr @src)  ]
SEM GrExpr | FetchField
  lhs.equations    =  case @lhs.targetInfo of
                        InVar tvar  ->  [ IsSelection tvar (getNr @nm) @offset (fromJust @mbTag) ]
  
SEM GrExpr | Store  
  lhs.location     =  @lhs.location + 1  
  lhs.heapEqs      =  case @val.termInfo of
                        InNode stag snms  -> [ WillStore @lhs.location stag snms ]
  lhs.equations    =  case @lhs.targetInfo of
                        InVar tvar        -> [ IsKnown tvar (AbsLocs (Set.singleton @lhs.location)) ] 
SEM GrGlobal | Global 
  lhs.location     =  @lhs.location + 1
  lhs.heapEqs      =  case @val.termInfo of
                        InNode stag snms  ->  [ WillStore @lhs.location stag snms ]
  lhs.equations    =                          [ IsKnown (getNr @nm) (AbsLocs (Set.singleton @lhs.location)) ]
    
SEM GrExpr | Call  
  lhs.equations    =  case @lhs.targetInfo of
                        InVar  tvar       -> [ IsSuperset tvar (getNr @nm) ]
                        InNode ttag tnms  -> buildSelectEquations (getNr @nm) ttag tnms

SEM GrExpr | FFI
  loc.nodemap      =  Map.fromList ( [ (con, [ AbsBasic | con==GrTag_Unboxed ] ) | con <- @tagL ] )
  lhs.equations    =  case @lhs.targetInfo of
                        InVar tvar        -> [ IsKnown tvar (AbsNodes @loc.nodemap) ]
                        InNode ttag tnms  -> zipWith IsKnown tnms (fromJust (Map.lookup ttag @loc.nodemap))

SEM GrExpr | Eval
  lhs.equations    =  case @lhs.targetInfo of
                        InVar tvar  -> [ IsEvaluation tvar (getNr @nm) ]

SEM GrExpr | Apply  
  lhs.equations    =  case @lhs.targetInfo of
                        InVar tvar ->  [ IsApplication (Just tvar) (getNr @nm : map fromInVar @argL.valsInfo) ]
\end{code}
\caption{Definition of constraint equations for various expression types (discussed in section~\ref{sec.collect})}
\label{fig.equations}
\end{figure*}



We are now ready to discuss the twelve syntactic positions where
equations originate, as defined in figure~\ref{fig.equations}.
In the case of a |Unit| or |UpdateUnit| we distinguish
the four combinations of target pattern (variable or node)
and source term (variable or node). When both are variables, the
target is constrained to be able hold the same value as the source;
when the target is a variable and the source is a node, 
the target should be able to hold that node. If, on the contrary, the
target is a node with explicit arguments, and the source is a
variable, all the arguments of the node that are not wildcards should be projections of the source
variable.
These constraints are generated by the following auxiliary function:
\begin{code}
buildSelectEquations 
  :: Variable -> GrTag -> [Variable] -> Equations
buildSelectEquations svar ttag tnms
  = [  IsSelection tvar svar i ttag
    |  (tvar,i) <- zip tnms [0..]
    ,  tvar /= wildcard
    ]
\end{code}
Finally, when both target and source are full nodes,
corresponding arguments should unify.
This is handled by another auxiliary function:
\begin{code}
buildUnifyEquations 
  :: [Maybe Variable] -> [Variable] -> Equations
buildUnifyEquations snms tnms
  = [  case mbSvar of
         Nothing    -> IsKnown     tvar AbsBasic
         Just svar  -> IsSuperset  tvar svar
    |  (tvar,mbSvar) <- zip tnms snms
    ,  tvar /= wildcard
    ]
\end{code}
In the case of an |UpdateUnit| expression there is one
more constraint, setting the destination variable of the
update equal to that of the source variable.

The situation arising from an alternative in a |Case| expression
is very much like the third subcase of a |Unit| expression:
the fields of the target node (which come from the pattern in
each alternative) are projections of the value of the
scrutinee, that we so carefully passed down in
the tree before.

We now turn to the three variants of |Fetch| expressions.
When a complete node is fetched, the target variable should be
equal to the value fetched.
For a |FetchNode| the target is the inherited target
(i.e., the next |Seq| pattern or result of a function |Bind|ing),
for a |FetchUpdate| the target is specified in the expression.
In case of a |FetchField| of a single field, that field should
be a projection from the source.

The next semantic rule, still in figure~\ref{fig.equations},
states that for a |Store| expression we need a new uniquely
numbered location.
A heap equation is generated that states that this location indeed
stores the value, and a normal equation is generated
that states that the target variable is a pointer to this location.

The situation for a |Global| variable definition is quite the same,
which is why we define these situations adjacently in
figure~\ref{fig.equations} (the AG preprocessor allows to handle
the cases |Expr| non-contiguously, which we
happily use here to group similar rules).

In the case of a |Call| to a Grin function or an |FFI| call
to a foreign function we distinguish the cases 
that the target is a variable or a complete node.
The final two cases in figure~\ref{fig.equations}
state that |Eval| and |Apply| expressions give rise to
corresponding constraints.

What is not handled in the cases discussed above,
is that actual parameters should agree to formal parameters.
The |Call| expression handled in figure~\ref{fig.equations} only
matched the result, not the arguments.
Function calls can either occur directly in a |Call| expression,
or be postponed by way of a thunk node.
Thunk nodes are recognizible by their tag, which is either
|Fun|, |PApp| or |App| (but not |Con| or one of the
other special tags).


We define a tree walk that collects the relevant calls and
tagged nodes. Conceptually this is a separate tree walk,
but it is merged by the AG preprocessor with the tree walk
defined earlier.
We declare synthesized attributes to collect |allCalls| and
|fpaNodes| (nodes with tags that indicate a thunk)
for nearly all syntactical positions,
because nodes are introduced at many places,
and the collections need to be passed up the tree:
\begin{code}
ATTR AllTerm AllExpr AllDef GrModule 
  SYN allCalls  USE (++) [] :: [(Variable, [Maybe Variable])]
  SYN fpaNodes  USE (++) [] :: [NodeInfo (Maybe Variable)]

\end{code}
Thanks to the |USE| clause, we only need to specify the
locations where calls and nodes are actually introduced:
\begin{code}  
SEM GrExpr  | Call    
  lhs.allCalls  =  [ (getNr @nm, @argL.vars) ]
SEM GrTerm  |  Node   
  lhs.fpaNodes  =  if    @tag.isfpa 
                   then  [ InNode @tag @fldL.vars ] 
                   else  []
\end{code}
An auxiliary attribute is used to decide which nodes are relevant
to collect:
\begin{code}
ATTR GrTag 
  SYN isfpa :: Bool
SEM GrTag
  | Fun PApp App      lhs.isfpa  = True
  | Con Hole Unboxed  lhs.isfpa  = False
\end{code}
Now the final set of equations is the combination of
constraints that were gathered in the tree walk
(that is, the synthesized |equations| from the entire module |mod|),
and those that arise from direct calls, |Fun|, |PApp| and |App| thunk nodes:
\begin{code}
SEM Program  |  Prog
  lhs.equations 
   = @mod.equations
     ++
     [  IsSuperset x y
     |  (funnr, args) <- @mod.allCalls
     ,  (x, Just y) <- zip [funnr + 1 ..] args
     ]
     ++
     [  IsSuperset x y
     |  (InNode (GrTag_Fun nm) args) 
            <- @mod.fpaNodes
     ,  (x, Just y) <- zip [getNr nm + 1 ..] args
     ]
     ++
     [  IsSuperset x y
     |  (InNode (GrTag_PApp needs nm) args) 
            <- @mod.fpaNodes
     ,  (x, Just y) <- zip [getNr nm + 1 ..] args
     ]
     ++ 
     [  IsApplication Nothing (map fromJust args)
     |  (InNode GrTag_App args) 
            <- @mod.fpaNodes
     ]
\end{code}
Note that we exploit the fact that the function and its arguments
are numbered consecutively: the arguments are numbered from
one more than the function number onwards.
Without this convention, the correspondance between the
number of a function and those of its parameters
could have been established as a mapping 
that could have been defined as yet another synthesized
attribute of bindings.

The trickiest equations are generated in the fifth concatenated list:
it states that the arguments of an |App| node represent an 
application, although it is not statically known where the
result is stored.







\subsection{Solve the constraint equations}\label{sec.solution}

Now we've collected all equations,
we can proceed to solve them.
The solution process is wrapped in function |solveEquations|.
It takes the two lists of equations that were collected in the tree walk,
and two integers that are the number of |Variable|s and |Location|s.
These were determined in an earlier stage where
variables are numbered (trivial, not shown in this paper),
and as synthesized attribute |location| in the tree walk.
\begin{figure*}
\begin{code}
envChanges :: Equation -> AbstractEnv s -> AbstractHeap s -> ApplyMap -> ST s [(Variable,AbstractValue)]
envChanges equat env heap applyMap
  = case equat of
      IsKnown         d av         ->  return [(d, av)]

      IsSuperset      d v          ->  do  {  av <- readArray env v
                                           ;  return [(d, av)]
                                           }
      IsSelection     d v i t      ->  do  {  av <- readArray env v
                                           ;  let res = absSelect av i t
                                           ;  return [(d,res)]
                                           }
      IsConstruction  d t as       ->  do  {  vars <- mapM (maybe (return AbsBasic) (readArray env)) as
                                           ;  let res = AbsNodes (Map.singleton t vars)
                                           ;  return [(d,res)]
                                           }
      IsEvaluation    d v          ->  do  {  av   <- readArray env v
                                           ;  res  <- absDeref av
                                           ;  return [(d,res)]
                                           }
      IsApplication mbd (f:as)     ->  do  {  av         <-  readArray env f
                                           ;  absFun     <-  case mbd of
                                                               Nothing  -> absDeref av
                                                               Just _   -> return av
                                           ;  absArgs    <-  mapM (readArray env) as
                                           ;  (sfx,res)  <-  absCall absFun absArgs
                                           ;  return $ (maybe id (\d->((d,res):)) mbd) sfx
                                           }
\end{code}
\begin{code}
    where
    absSelect av i t   =  case av of
                            AbsNodes  ns  -> maybe AbsBottom (!!i) (Map.lookup t ns)
                            AbsBottom     -> av
                            AbsError _    -> av
    absDeref av        =  case av of
                            AbsLocs ls    ->  do  { vs <- mapM (readArray heap) (Set.toList ls)
                                                  ; return (mconcat (map (filterNodes isFinalTag) vs))
                                                  }
                            AbsBottom     ->  return av
                            AbsError _    ->  return av
    absCall f args     =  do {  ts <- mapM addArgs (getNodes (filterNodes isPAppTag f))
                             ;  let (sfxs,avs) = unzip ts
                             ;  return (concat sfxs, mconcat avs)
      	                     }
      where  addArgs (tag@(GrTag_PApp needs nm) , oldArgs) 
               =  do  {  let  n         = length args
                              newtag    = GrTag_PApp (needs-n) nm
                              funnr     = getNr nm
                              sfx       = zip  [funnr+1+length oldArgs ..] args
                      ;  res <-  if    n<needs
                                 then  return $ AbsNodes (Map.singleton newtag (oldArgs++args))
                                 else  readArray env funnr
                      ;  return (sfx, res)
                      }
             getNodes av  =  case av of  
                               AbsNodes n  -> Map.toAscList n
                               AbsBottom   -> []
\end{code}
\caption{Selection of change candidates for the abstract environment during fixpoint iteration (discussed in section~\ref{sec.solution})}
\label{fig.envChanges}
\end{figure*}

The |solution| function starts with creating two arrays,
initially holding only |AbsBottom| values, to store the
abstract values of all variables and locations, respectively.
Then a fixpoint iteration is done, processing in each step
all constraints from both sets of equations.
The fixpoint function is parameterized not only by the two
sets of equations, but also by two procedures that process
an equation.
These procedures call function |envChanges| or |heapChange|
respectively, to obtain the changes on the variables or locations
that need to be made.
\begin{code}
solveEquations ::  Int -> Int 
                   -> Equations -> HeapEquations 
                   -> (AbsEnv,AbsHeap,Int)
solveEquations lenEnv lenHeap eqs1 eqs2
=  runST $
   do  { env   <- newArray (0, lenEnv   - 1) AbsBottom
       ; heap  <- newArray (0, lenHeap  - 1) AbsBottom
       ; let procEnv equat
             = do  { cs  <- envChanges equat env heap
                   ; bs  <- mapM (procChange env) cs
                   ; return (or bs)
                   }
             procHeap equat
             = do  { cs  <- heapChange equat env
                   ; b   <- procChange heap cs
                   ; return b
                   }
       ; count <- fixpoint eqs1 eqs2 procEnv procHeap
       ; return (env, heap, count)
       }
\end{code}
In the processing procedures, the change candidates obtained
(exactly one in the case of an |heapEquation|, 
possibly more in the case of an |Equation|)
are fed into function |procChange| to apply the change.
It can be generically used for either an environment variable
or a heap location.
This function only changes the array (environment or heap)
when an element (variable or location) is actually changed,
and returns the a boolean that indicates whether there was a change:
\begin{code}
procChange arr (i,e1) =
   do { e0 <- readArray arr i
      ; let   e2       =  e0 `mappend` e1
              changed  =  e0 /= e2
      ; when changed (writeArray arr i e2)
      ; return changed
      }
\end{code}
The fixpoint function uses these booleans to decide whether to
stop or continue processing all equations again:
as long as one of the equations results in a change, the
iteration is continued.
\begin{code}
fixpoint eqs1 eqs2 proc1 proc2 
=  fix 0
   where  fix count 
          =  do
             {  let step1  b i  = proc1  i >>= return . (b||)
             ;  let step2  b i  = proc2  i >>= return . (b||)
             ;  changes1  <- foldM step1  False eqs1
             ;  changes2  <- foldM step2  False eqs2
             ;  if    changes1 || changes2
                then  fix (count+1)
                else  return count
             }
\end{code}
What remains to be done is to describe how change candidates
are selected for each equation.
This is implemented in function |heapChange| below and
function |envChanges| if figure~\ref{fig.envChanges}.



We start with the changes for heap locations.
Function |heapChange| dissects an |HeapEquation|,
that states that at some location a node with given tag
and argument variables is stored.
If the node is a function thunk, i.e.\ the tag is |GrTag_Fun|,
the location can later be updated with the function result.
Possible nodes that this location can point to are thus
all function results for this function.
We therefore consult the environment to obtain the `abstract result'
for this function.
Regardless of the value of the tag, the location mentioned in the equation
certainly points initially to the node that is constructed.
An `abstract node' is therefore constructed by creating a singleton
map from the node to the abstractly evaluated arguments.
\begin{code}
heapChange ::  HeapEquation -> AbstractEnv s 
               -> ST s (Location,AbstractValue)
heapChange (WillStore locat tag args) env 
 = do  { let mbres       =   tagFun tag
       ; absArgs         <-  mapM getEnv args
       ; absRes          <-  getEnv mbres
       ; let absNode     =   AbsNodes 
                               (Map.singleton tag absArgs)
       ; return (locat, absNode `mappend` absRes)
       }
       where
       tagFun (GrTag_Fun nm)  =  Just (getNr nm)
       tagFun _               =  Nothing
       getEnv Nothing         =  return AbsBottom
       getEnv (Just v)        =  readArray env v
\end{code}
The changes of the abstract variables that arise from
processing an |Equation| are determined by function |envChanges|
in figure~\ref{fig.envChanges}, which we will now discuss.
First, note that this function returns a list of changes,
unlike function |heapChange| above, which returns only a single change.
For five out of six possible equation types this list 
is a singleton, however.
Only for the |IsApplication| case of an equation, multiple changes
may arise from one equation.

For the first equation type |IsKnown|, where a variable is known 
to (possibly) have some abstract value, 
the variable is simply tupled with that abstract value to indicate
a necessary change.
For the second equation type |IsSuperset|, where a variable |d| possibly
can be equal to another variable |v|, 
the current approximation of |v| is looked up in the abstract environment,
and designated as a needed change for |d| as well.
For an |IsSelection| equation, the variable |v| is abstractly evaluated
to obtain an abstract node. From that abstract node the desired field
is abstractly selected.
The case of an |IsConstruction| equation is similar to 
the |WillStore| heap equation discussed above, in that 
an abstract node is created from the known tag and the abstractly 
evaluated argument variables.

The fifth equation type is |IsEvaluation d v|, 
which states that |d| may be used to hold the evaluation result of 
thunk nodes pointed to by |v|.
Here, we first abstractly evaluate |v| to obtain the abstract pointers.
These pointers are then abstractly dereferenced, 
that is looked up in the abstract heap.
This results in all abstract nodes the locations can point to.
By the design of the processing of heap equations, 
this is not only the thunk node, but also the possible
evaluation results of it.
As the |IsEvaluation| equation is supposed obtain the evaluation
results only, the list of all abstract nodes the locations can point
to is filtered such that only those with a final tag (like |GrTag_Con|)
remain, and those with thunk tag (like |GrTag_Fun|) are discarded.
The filtering is done by an auxiliary function:
\begin{code}
filterNodes ::  (GrTag->Bool) 
                -> AbstractValue -> AbstractValue
filterNodes p (AbsNodes nodes) 
  = AbsNodes (Map.filterWithKey (const . p) nodes)
filterNodes p av
  = av
isFinalTag, isPAppTag :: GrTag -> Bool
isFinalTag  (GrTag_Fun _)      = False
isFinalTag   GrTag_App         = False
isFinalTag  _                  = True
isPAppTag   (GrTag_PApp _ _)   = True
isPAppTag   _                  = False
\end{code}
The last equation type, |IsApplication|, is the trickiest.
Remember that it was introduced in section~\ref{sec.collect} in two situations:
(1) at every |App| expression in the Grin program, 
where the |Maybe Variable| destination is |Just| a variable name,
and 
(2) at every constructed node in the Grin program with |App| tag,
where the destination is |Nothing|.

Also remember from section~\ref{sec.constraintlang} 
that |IsApplication mbv (f:as)| means that |f| is a variable
which refers to a function which is applied to
values referred to by variables |as|
(and the result may be stored in variable |v| if |mbv| is |Just v|).

The first thing that needs to be done is therefore to
evaluate |f| and |as| abstractly.
If the equation was introduced from situation (2),
the function variable also needs to be dereferenced abstractly.
This gives us an abstract function |absFun| and abstract arguments |absArgs|.
Function |absCall| now can abstractly apply the former to the latter.

Doing an abstract call amounts to filtering the partial-application thunk nodes
from the possible nodes that can represent the function, 
and adding the extra arguments by way of function |addArgs|.
If, after adding the new parameters, the function is still not fully saturated,
a new abstract node is constructed, having a |PApp| tag with lower |needs|
than the original one. 
If the function happens to be fully saturated, the possible results are read from the environment.
The resulting nodes (either the newly constructed, or those read)
is tupled with the destination variable to indicate a necessary change,
at least in situation (1) where such a variable exists.

But there are other changes that need to be taken in account as well.
In the abstract call, new associations are made between arguments and
formal parameters, that are not otherwise detected.
This is why the |absCall| and |addArgs| functions, in addition to the function result,
also return changes that take care of new possible abstract values for argument variables.
It is because of these `side effects' (designated |sfx| in figure~\ref{fig.envChanges})
that function |envChanges| sometimes returns more than one change.






\section{Discussion and future work}


How to keep the number of alternatives limited: specialized versions

Smart ordering of alternatives:
binary tree, most frequently first, or combined: Huffmancode-style

Which cases are frequent:
cons more than nil; empirical gathering of data during test run, for use in subsequent compilations

Return is also an indirect jump and can be avoided by a `came-from analysis'







\acks

The authors thank Christof Douma for
writing an initial version of the algorithm
described in this work.



\begin{thebibliography}{}




\bibitem[Bird 1984]{bird}
Bird, Richard S.
`Using Circular Programs to Eliminate Multiple Traversals of Data',
Acta Informatica {\bf 21}, 239--250.



\bibitem[Boquist and Johnsson 1996]{boquist1996}
Boquist, Urban and Thomas Johnsson.
`The GRIN Project: A Highly Optimising Back End For Lazy Functional Languages', 
Workshop on Implementation of Functional Languages, IFL 1996.
Springer LNCS 1268. 


\bibitem[Boquist 1999]{boquist1999}
Boquist, Urban. 
Code Optimisation Techniques for Lazy Functional Languages, 
PhD Thesis Chalmers University, G\"oteborg March 1999.

\bibitem[Dijkstra 2005]{ehc}
Dijkstra, Atze.
Stepping through Haskell,
PhD Thesis Utrecht University, November 2005.

\bibitem[Douma 2006]{douma}
Douma, Christof.
Exceptional GRIN, 
Master's Thesis Utrecht University, April 2006.


\bibitem[Jones 1999]{thih}
Jones, Mark P.
`Typing Haskell in Haskell',
Haskell Workshop 1999.

\bibitem[Knuth 1968]{knuth}
Knuth, D.E.
`Semantics of Context-free Languages'.
Mathematical Systems Theory {\bf 2}, 127--145.


\bibitem[Marlow and Peyton Jones 2006]{marlow}
Marlow, Simon and Simon Peyton Jones.
`Making a fast curry: push/enter vs.\ eval/apply for higher-order languages',
JFP2006/ICFP2004.


\bibitem[Peyton Jones 1992]{peytonjones}
Peyton Jones, Simon.
`Spineless Tagless G-machine',
 JFP 1992.

\bibitem[Swierstra et al. 1998]{agsyst}
Swierstra, S.\ Doaitse,
Pablo R.\ Azero Alocer,
and Jo\~ao Sariava.
`Designing and Implementing Combinator Languages'.
In: Advanced functional programming, AFP98.
Springer LNCS 1608.


\end{thebibliography}

\end{document}





\begin{code}
\end{code}